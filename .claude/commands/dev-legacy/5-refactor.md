---
description: Refactors implemented features with Context7 research for security, performance, quality, and error handling improvements. Non-breaking changes only, automatic rollback if tests fail
---

# Refactor Skill

## Overview

This skill guides systematic code refactoring after successful feature implementation. It loads context from `.workspace/features/` (generated by /1-plan and /2-code skills), performs Context7 research for security, performance, and quality improvements, evaluates research relevance, creates a refactor plan using sequential thinking, and applies non-breaking improvements to the codebase. The skill operates in a structured workflow: preparation, Context7 research, relevance evaluation, planning, preview/approval, implementation, testing, and documentation.

The skill focuses on four priority areas: Security (OWASP, validation), Performance (N+1 queries, caching), Code Quality (design patterns, SOLID), and Error Handling (retry logic, resilience patterns). All changes must be non-breaking - if tests fail after refactoring, immediate rollback occurs.

## When to Use

This skill activates when:

**Trigger:**
- `/5-refactor` command in Claude Code

**Requirements:**
- `/1-plan` skill has generated context (`.workspace/features/{name}/01-intent.md` + `01-research.md`)
- `/2-code` skill has generated implementation (`.workspace/features/{name}/02-implementation.md`)
- Feature code exists and tests are passing
- No blocking bugs or issues

**NOT for:**
- Fixing broken tests (use /3-verify first)
- Adding new features (use /1-plan then /2-code)
- Architecture redesigns (requires new /1-plan cycle)
- Breaking changes (requires new /1-plan cycle)

## Workflow

The skill operates through eight phases. Execute each phase sequentially.

### Phase 0: Feature Selection

**Goal:** Let user select which feature to refactor from available features.

**Steps:**

1. **Validate features directory exists:**
   ```bash
   ls .workspace/features/
   ```

   **If directory does not exist:**
   ```
   âŒ NO FEATURES FOUND

   The directory .workspace/features/ does not exist.
   First run /1-plan and /2-code to implement a feature.
   ```
   â†’ EXIT skill gracefully

2. **Check if feature name provided with command:**

   **If user ran `/5-refactor {feature-name}`:**
   - Skip numbered list
   - Use provided feature name directly
   - Validate it exists in `.workspace/features/{feature-name}/02-implementation.md`
   - If valid: proceed to step 5 (confirm selection)
   - If invalid: show error, then fall back to numbered list (step 3)

   **If user ran `/5-refactor` without arguments:**
   - Proceed to step 3 (show numbered list)

3. **List available features (only if no feature name provided):**
   - Scan `.workspace/features/` for all folders with `02-implementation.md`
   - For each feature, check if `.worktree` file exists and read worktree path
   - Show numbered list with feature status AND worktree info

   **Worktree column logic:**
   - If `.workspace/features/{name}/.worktree` exists â†’ show worktree path
   - If no `.worktree` file â†’ show "(no worktree)"

   **Build options from available features:**
   - Scan `.workspace/features/` for all folders
   - For each folder, check if `02-implementation.md` exists
   - Build dynamic option list with worktree info

   **Use AskUserQuestion tool:**
   - header: "Feature Selectie"
   - question: "Welke feature wil je refactoren?"
   - options: (dynamically built from scan results)
     - For each implemented feature:
       - label: "{feature-name} (Recommended)" (first implemented feature gets Recommended)
       - description: "âœ“ GeÃ¯mplementeerd{, N parts/extends/changes}" (if applicable)
     - For each non-implemented feature:
       - label: "{feature-name}"
       - description: "âœ— Niet geÃ¯mplementeerd - run /2-code eerst"
     - Always add last option:
       - label: "Uitleg vraag"
       - description: "Leg uit wat feature selectie betekent"
   - multiSelect: false

   **Example options (dynamic):**
   ```
   options:
     - label: "checkout (Recommended)", description: "âœ“ GeÃ¯mplementeerd, 2 parts"
     - label: "user-profile", description: "âœ“ GeÃ¯mplementeerd"
     - label: "notifications", description: "âœ— Niet geÃ¯mplementeerd - run /2-code eerst"
     - label: "Uitleg vraag", description: "Leg uit wat feature selectie betekent"
   ```

   **Handle "Uitleg vraag" response:**
   ```
   ğŸ“– FEATURE SELECTIE UITLEG

   Je kiest hier welke feature je wilt refactoren. Features zijn
   functionele onderdelen van je applicatie die eerder zijn gepland
   (/1-plan) en geÃ¯mplementeerd (/2-code).

   Features met "âœ“ GeÃ¯mplementeerd" kunnen worden gerefactored.
   Features met "âœ— Niet geÃ¯mplementeerd" moeten eerst worden
   gebouwd met /2-code.

   Parts/extends/changes zijn sub-onderdelen van een feature die
   apart kunnen worden gerefactored.
   ```
   â†’ Return to feature selection

4. **Handle user selection:**
   - If number: map to feature name â†’ proceed to step 5
   - If name only: validate exists â†’ proceed to step 5
   - If invalid: show error and re-prompt

5. **Auto-detect part/extend/change (always runs after feature selection):**

   **If feature has NO parts/extends/changes:** Skip to step 6

   **If feature HAS parts/extends/changes:**
   - Read `01-intent.md` to find all sections (`## Part: {name}`, `## Extend: {name}` or `## Change: {name}`)
   - For each section, check refactor status in `05-refactor.md`:
     - If section exists â†’ `âœ“ Refactored`
     - If section missing â†’ `â—‹ Not refactored`
   - **Auto-select** the first implemented part/extend/change that hasn't been refactored yet

   ```
   ğŸ“‹ AUTO-DETECTED SECTION

   Feature: checkout
   Sections: 2 total (1 refactored, 1 pending)

   | # | Name | Type | Status |
   |---|------|------|--------|
   | 1 | 01-cart-models | Part | âœ“ Refactored |
   | 2 | 02-payment-backend | Part | â—‹ Not refactored â† NEXT |

   Auto-selected: 02-payment-backend (part)
   ```

   **If all parts/extends/changes already refactored:**
   ```
   âœ… ALL SECTIONS REFACTORED

   Feature: checkout
   All parts/extends/changes have already been refactored.

   Pipeline complete for this feature!
   ```
   â†’ EXIT skill gracefully

6. **Confirm selection:**
   ```
   âœ… SELECTED: {feature-name} {extend/change if applicable}

   Checking worktree...
   ```

7. **Verify correct worktree (if .worktree file exists):**

   **Skip if:** task_type is EXTEND or CHANGE (these use parent feature's worktree)

   **Steps:**

   a. **Check for .worktree file:**
      ```bash
      cat .workspace/features/{feature-name}/.worktree
      ```
      - If file exists â†’ read worktree path
      - If file doesn't exist â†’ continue without worktree (legacy mode)

   b. **Compare current directory with worktree path:**
      ```bash
      # Get current directory (absolute path)
      pwd
      ```
      - If current directory matches worktree path â†’ continue to Phase 1
      - If current directory does NOT match â†’ prompt user to switch

   c. **If NOT in correct worktree:**
      ```
      âš ï¸ WRONG WORKTREE

      Feature "{feature-name}" has a dedicated worktree:
      {worktree-path}

      You are currently in:
      {current-directory}
      ```

      Use AskUserQuestion tool:
      - header: "Worktree"
      - question: "Je zit niet in de juiste worktree. Wat wil je doen?"
      - options:
        - label: "Open worktree (Recommended)"
          description: "Open {worktree-path} in nieuw VSCode venster"
        - label: "Toch hier doorgaan"
          description: "Werk in huidige directory (niet aanbevolen)"
        - label: "Annuleren"
          description: "Stop en switch handmatig"
        - label: "Uitleg"
          description: "Leg uit wat worktrees zijn"
      - multiSelect: false

      **If "Open worktree":**
      ```bash
      code "{worktree-path}"
      ```
      Report:
      ```
      ğŸ“‚ WORKTREE OPENED

      VSCode venster geopend voor: {worktree-path}

      Switch naar dat venster en run /5-refactor {feature-name} opnieuw.
      ```
      â†’ EXIT skill (user continues in other window)

      **If "Toch hier doorgaan":**
      Report:
      ```
      âš ï¸ Continuing in current directory (worktree ignored)
      ```
      â†’ Continue to Phase 1 (with warning logged)

      **If "Annuleren":**
      â†’ EXIT skill gracefully

   d. **If IN correct worktree (or no worktree defined):**
      ```
      âœ… WORKTREE VERIFIED

      Working in: {current-directory}
      Feature: {feature-name}

      â†’ Loading context...
      ```

**Output:**

```text
âœ… FEATURE SELECTED

Feature: {name}
[If extend:] Extend: {extend-name}
[If change:] Change: {change-name}
Worktree: {worktree-path} (verified)

â†’ Loading context...
```

---

### Phase 1: Context Loading

**Goal:** Load all relevant context for the selected feature.

**Steps:**

1. **Detect mode and set file paths:**

   **Normal feature mode:**
   ```
   Intent: .workspace/features/{name}/01-intent.md
   Research: .workspace/features/{name}/01-research.md
   Implementation: .workspace/features/{name}/02-implementation.md
   Refine (optional): .workspace/features/{name}/04-refine.md
   Refactor output: .workspace/features/{name}/05-refactor.md
   ```

   **Part mode (sections within parent files):**
   ```
   All files in feature folder (parts are sections, not folders):
   - Intent: .workspace/features/{feature}/01-intent.md (look for "## Part: {NN}-{name}" section)
   - Research: .workspace/features/{feature}/01-research.md (look for "## Part: {NN}-{name}" section)
   - Implementation: .workspace/features/{feature}/02-implementation.md (look for section or append)
   - Refine (optional): .workspace/features/{feature}/04-refine.md (look for section or append)
   - Refactor output: .workspace/features/{feature}/05-refactor.md (append "## Part: {NN}-{name}" section)
   ```

   **Extend/Change mode (context in appended sections):**
   ```
   All files in parent feature folder:
   - Intent: .workspace/features/{parent}/01-intent.md (look for "## Extend: {name}" section)
   - Research: .workspace/features/{parent}/01-research.md (look for section)
   - Implementation: .workspace/features/{parent}/02-implementation.md (look for section)
   - Refine (optional): .workspace/features/{parent}/04-refine.md (look for section)
   - Refactor output: Append "## Extend: {name}" section to .workspace/features/{parent}/05-refactor.md
   ```

2. **Validate required files exist:**

   Required files:
   - `01-intent.md` - User requirements
   - `01-research.md` - Context7 research
   - `02-implementation.md` - Implementation details

   **If context file missing:**
   ```
   âŒ CONTEXT FILE MISSING

   File not found: {context-file-path}
   This file is generated by /1-plan.
   First run /1-plan for this feature.
   ```
   â†’ EXIT skill gracefully

   **If implementation file missing:**
   ```
   âŒ IMPLEMENTATION FILE MISSING

   File not found: {implementation-file-path}
   This file is generated by /2-code.
   First run /2-code for this feature.
   ```
   â†’ EXIT skill gracefully

   **If implementation file is empty or contains no file paths:**
   ```
   âŒ IMPLEMENTATION FILE EMPTY

   File contains no code files: {implementation-file-path}
   The file exists but has no file paths to refactor.
   Check if /2-code was executed correctly.
   ```
   â†’ EXIT skill gracefully

3. **Load ALL documentation files in feature folder:**

   Read all `.md` files in the feature folder to get complete context:
   ```bash
   # List all .md files in feature folder
   ls {feature-folder}/*.md
   ```

   - Read `00-overview.md` for feature summary (if exists)
   - Read `01-intent.md` for requirements (what was built)
   - Read `01-research.md` for patterns (how it was built)
   - Read `02-implementation.md` for implementation details
   - Read `03-verify.md` for test results (if exists)
   - Read `04-refine.md` for refinement changes (if exists)
   - Read any other `.md` files present

4. **Build pipeline files list (for scope tracking):**

   Extract all code file paths from:
   - `02-implementation.md` â†’ files created/modified during coding
   - `04-refine.md` â†’ files modified during refinement (if exists)

   Store as `pipeline_files` list. These are files that belong to THIS feature.
   All other files encountered during refactoring are "external files".

   ```
   pipeline_files = [
     "src/controllers/RecipeController.php",
     "src/models/Recipe.php",
     "src/services/RecipeService.php",
     ...
   ]
   ```

5. **Read all CODE files mentioned in implementation log:**
   - Extract file paths from implementation file
   - Read each file to understand current implementation
   - **Report progress for large file sets:**
     - If > 5 files: show progress every 5 files
     - Format: `Reading code files... ({current}/{total})`
   - Note architectural patterns used
   - Identify areas for potential improvement

**Output:**
```
ğŸ” CONTEXT LOADED

| Field | Value |
|-------|-------|
| **Mode** | [FEATURE / PART / EXTEND / CHANGE] |
| **Feature/Part/Extend/Change** | {name} |
| **Parent feature** | {parent} (if applicable) |

**Documentation files:**

| File | Status |
|------|--------|
| 00-overview.md | âœ“ / not present |
| 01-intent.md | âœ“ |
| 01-research.md | âœ“ |
| 02-implementation.md | âœ“ |
| 03-verify.md | âœ“ / not present |
| 04-refine.md | âœ“ / not present |

| Metric | Value |
|--------|-------|
| **Pipeline files tracked** | [count] files |
| **Code files read** | [list of files] |
| **Refactor output** | {refactor-output-path} |

â†’ Ready for Context7 research.
```

---

### Phase 2: Context7 Research

**Goal:** Research best practices for security, performance, quality, and error handling using parallel agents.

**IMPORTANT:** Use Task tool to spawn 4 specialized research agents in parallel.

**Metric Definitions:**

Before proceeding, understand these two metrics used throughout this phase:

- **Coverage (0-100%)**: Measures *breadth* of research - what percentage of relevant topics were found in Context7 documentation. Higher coverage means more topics were successfully researched.
  - 90-100%: Excellent - comprehensive documentation found for all areas
  - 75-89%: Good - most topics covered with some gaps
  - 50-74%: Moderate - significant gaps, may need additional research
  - <50%: Poor - insufficient documentation found

- **Confidence (0-100%)**: Measures *quality/applicability* of findings - how certain we are that the recommendations apply to THIS specific codebase. Higher confidence means findings are more actionable.
  - 90-100%: High - framework-specific patterns that directly apply
  - 80-89%: Good - relevant patterns with minor adaptation needed
  - 70-79%: Moderate - general patterns that may or may not apply
  - <70%: Low - theoretical/generic advice, use with caution

**Steps:**

0. **Check Stack Baseline (before spawning agents):**

   ```bash
   ls .claude/research/stack-baseline.md
   ```

   **If baseline EXISTS:**
   - Read `.claude/research/stack-baseline.md`
   - Check "Valid until" date
   - **If valid:** Store baseline content for agent prompts, set `baseline_available = true`
   - **If expired:** Show warning and decision prompt:
     ```
     âš ï¸ STACK BASELINE EXPIRED

     The stack baseline was valid until [date] but is now expired.
     ```

     **Use AskUserQuestion tool:**
     - header: "Baseline"
     - question: "Stack baseline is expired. How do you want to proceed?"
     - options:
       - label: "Use expired"
         description: "Continue with expired baseline (agents will note lower confidence)"
       - label: "Skip baseline"
         description: "Continue without baseline (agents will do full research)"
       - label: "Stop & refresh"
         description: "Stop and run /setup to regenerate baseline first"

     **Handle response:**
     - If user chooses "Use expired":
       - Set `baseline_available = true`
       - Set `baseline_expired = true`
       - Agents receive baseline but include note: "WARNING: Baseline is expired, validate recommendations against current docs"
       - All confidence scores reduced by 10% to reflect uncertainty
     - If user chooses "Skip baseline":
       - Set `baseline_available = false`
       - Log: "Proceeding without baseline, agents will do full research"
     - If user chooses "Stop & refresh":
       - EXIT skill with message: "Run /setup to refresh stack baseline, then re-run /5-refactor"

   **If baseline DOES NOT EXIST:**
   - Log: "No stack baseline found, agents will do full research"
   - Set `baseline_available = false`

1. **Prepare agent context:**

   **If baseline_available = true:**
   ```
   Feature/Part/Extend/Change: [name from Phase 1]
   Mode: [FEATURE / PART / EXTEND / CHANGE from Phase 1]

   Context loaded:
   - Context file: [path]
   - Implementation file: [path]
   - Refine file: [path if exists, or "not present"]
   - Code files: [list]

   Tech stack: [from CLAUDE.md]

   [If refine file exists:]
   REFINE CHANGES APPLIED:
   [Insert summary from 04-refine.md - what was adjusted and why]

   IMPORTANT: Consider refine changes when researching improvements.
   Code has been modified since initial implementation.

   STACK BASELINE AVAILABLE:
   [Insert baseline content from stack-baseline.md]

   IMPORTANT:
   - DO NOT research topics already covered in baseline above
   - SKIP Context7 queries for general framework patterns
   - FOCUS on code-specific issues in the loaded files
   - Research specialized topics NOT in baseline

   Your mission: Research [category] best practices and identify improvement opportunities in THIS CODE.
   ```

   **If baseline_available = false:**
   ```
   Feature/Part/Extend/Change: [name from Phase 1]
   Mode: [FEATURE / PART / EXTEND / CHANGE from Phase 1]

   Context loaded:
   - Context file: [path]
   - Implementation file: [path]
   - Refine file: [path if exists, or "not present"]
   - Code files: [list]

   Tech stack: [from CLAUDE.md]

   [If refine file exists:]
   REFINE CHANGES APPLIED:
   [Insert summary from 04-refine.md - what was adjusted and why]

   IMPORTANT: Consider refine changes when researching improvements.
   Code has been modified since initial implementation.

   NO STACK BASELINE - perform full research.

   Your mission: Research [category] best practices and identify improvement opportunities.
   ```

2. **Ask user which research areas to include:**

   **Use AskUserQuestion tool:**
   - header: "Research Focus"
   - question: "Welke onderzoeksgebieden wil je meenemen?"
   - options:
     - label: "Security (Recommended)"
       description: "OWASP patterns, input validation, injection prevention"
     - label: "Performance"
       description: "N+1 queries, caching, resource efficiency"
     - label: "Quality + Simplification"
       description: "Design patterns, SOLID, **code simplification** (removes over-engineering)"
     - label: "Error Handling"
       description: "Resilience patterns, retry logic, graceful degradation"
     - label: "Uitleg vraag"
       description: "Leg uit wat deze onderzoeksgebieden betekenen"
   - multiSelect: true

   **Handle "Uitleg vraag" response:**
   ```
   ğŸ“– ONDERZOEKSGEBIEDEN UITLEG

   **Security**: Zoekt naar beveiligingspatronen zoals OWASP Top 10,
   input validatie, SQL injection preventie, XSS bescherming.

   **Performance**: Zoekt naar optimalisatiepatronen zoals N+1 query
   preventie, caching strategieÃ«n, lazy loading, resource efficiency.

   **Quality + Simplification**: Zoekt naar code kwaliteitspatronen zoals SOLID principles,
   design patterns, maintainability, testbaarheid. **Detecteert ook over-engineering:**
   onnodige abstracties, helpers voor 1x gebruik, te veel layers, premature optimization.

   **Error Handling**: Zoekt naar foutafhandelingspatronen zoals retry
   logic, circuit breakers, graceful degradation, resilience patterns.
   ```
   â†’ Return to research area selection

3. **Spawn agents ONLY for selected areas (max 4, min 1):**

   **If "Security" selected â†’ spawn Agent: security-researcher**
   - Researches: OWASP patterns, input validation, injection prevention
   - Priority: Highest (35% weight)
   - Autonomous: Plans own Context7 queries, evaluates coverage

   **If "Performance" selected â†’ spawn Agent: performance-researcher**
   - Researches: N+1 queries, caching, query optimization
   - Priority: Second (30% weight)
   - Autonomous: Plans own Context7 queries, evaluates coverage

   **If "Quality" selected â†’ spawn Agent: quality-researcher**
   - Researches: Design patterns, SOLID, code organization, **code simplification**
   - Priority: Third (20% weight)
   - Autonomous: Plans own Context7 queries, evaluates coverage
   - **Simplification focus:** Detects over-engineering, unnecessary abstractions, premature optimization

   **If "Error Handling" selected â†’ spawn Agent: error-handling-researcher**
   - Researches: Retry logic, circuit breakers, resilience patterns
   - Priority: Fourth (15% weight)
   - Autonomous: Plans own Context7 queries, evaluates coverage

   **Weight redistribution when fewer than 4 areas selected:**
   - Redistribute weights proportionally among selected areas
   - Example: If only Security + Performance selected:
     - Security: 35/(35+30) = 54%
     - Performance: 30/(35+30) = 46%

4. **Wait for all agents to complete:**
   - Each agent returns structured output with findings
   - Each agent reports its own coverage score (0-100%)
   - Agents work autonomously using sequential-thinking
   - **Report progress as agents complete:**
     - Format: `Research agents: {completed}/4 complete`
     - Show which agent just finished: `âœ“ security-researcher complete (coverage: X%)`

**Output:**
```
ğŸ“š CONTEXT7 RESEARCH COMPLETE

**Agents spawned in parallel:**

| Agent | Coverage | Confidence |
|-------|----------|------------|
| security-researcher | [X]% | [Y]% |
| performance-researcher | [X]% | [Y]% |
| quality-researcher | [X]% | [Y]% |
| error-handling-researcher | [X]% | [Y]% |

â†’ Ready for relevance evaluation.
```

---

### Phase 3: Evaluate Research Relevance

**Goal:** Assess if Context7 research provides sufficient guidance for refactoring.

**Steps:**

1. **Initial evaluation with sequential-thinking:**

   Use `sequential-thinking` to calculate initial coverage score for each category:
   - Security research relevance (0-100%)
   - Performance research relevance (0-100%)
   - Quality research relevance (0-100%)
   - Error handling research relevance (0-100%)

   **Consider:**
   - How relevant is info to this specific codebase?
   - Sufficient depth or too surface-level?
   - Framework-specific or too generic?
   - Actionable or theoretical?

2. **Execute coverage evaluation script:**
   ```bash
   python3 scripts/evaluate_refactor_coverage.py \
     --security [coverage_score] \
     --performance [coverage_score] \
     --quality [coverage_score] \
     --error-handling [coverage_score] \
     --security-confidence [confidence_score] \
     --performance-confidence [confidence_score] \
     --quality-confidence [confidence_score] \
     --error-handling-confidence [confidence_score] \
     --format text
   ```

3. **Script returns:**
   - Overall coverage score (0-100%)
   - Overall confidence score (0-100%)
   - Decision: `proceed`, `unclear`, `additional_search`, or `revise`
   - Weakest areas (categories < 75% coverage OR < 80% confidence)
   - Recommendation

4. **Decision logic:**

   **A. proceed (>= 86% coverage AND >= 80% confidence):**
   - Continue to Phase 4 (Planning)

   **B. unclear (50-85% coverage) - SPAWN EVALUATION AGENTS:**

   When the initial score falls in the "unclear" range, spawn 3 evaluation agents
   in parallel for multi-perspective assessment:

   **Step B.1: Launch 3 agents in parallel (single message with 3 Task tool calls):**

   ```
   - Task(subagent_type="evaluate-optimist", prompt="[research findings + code context]
     Your mission: Evaluate what IS usable from this research.")

   - Task(subagent_type="evaluate-skeptic", prompt="[research findings + code context]
     Your mission: Evaluate what's MISSING from this research.")

   - Task(subagent_type="evaluate-pragmatist", prompt="[research findings + code context]
     Your mission: Evaluate what's ACTIONABLE from this research.")
   ```

   **Step B.2: Wait for all 3 agents to complete**

   **Step B.3: Calculate weighted final score:**
   ```
   Final Coverage = (optimist_score Ã— 0.30) + (skeptic_usability Ã— 0.30) + (pragmatist_score Ã— 0.40)
   ```

   Note: Pragmatist has highest weight (40%) because actionability is most important.

   **Step B.4: Decide based on final score:**
   - >= 75%: Proceed to Phase 4
   - 50-74%: Proceed with warning
   - < 50%: Present options to user (see "revise" case below)

   **C. additional_search (single category < 50% while others >= 75%):**

   Execute targeted research for weakest category only (max 1 retry cycle):

   1. Identify weakest category (lowest score < 50%)
   2. Spawn single targeted research agent for that category:
      - Use more specific Context7 queries based on actual code patterns found
      - Focus on framework-specific documentation (e.g., "Laravel N+1" not just "N+1")
      - Include code snippets from loaded files in query context
   3. Re-run steps 1-3 (evaluation + coverage script)
   4. **After 1 retry:**
      - If still < 50% â†’ proceed anyway with warning in output
      - If >= 50% â†’ proceed (with or without warning based on final score)

   **D. revise (< 50% overall):**

   Coverage too low for reliable refactoring. Present user with options:
   ```
   âš ï¸ LOW COVERAGE ({X}%)

   The Context7 research provides insufficient guidance for this codebase.
   ```

   **Use AskUserQuestion tool:**
   - header: "Low Coverage"
   - question: "Coverage is too low for reliable refactoring. How do you want to proceed?"
   - options:
     - label: "Retry search"
       description: "Try broader search terms (1 retry)"
     - label: "Continue anyway"
       description: "Proceed with low confidence (not recommended)"
     - label: "Stop"
       description: "Accept current code quality and exit"

   **Handle response:**
   - If user chooses "Retry search" â†’ execute additional_search logic (1 retry only, no further retries)
   - If user chooses "Continue anyway" â†’ proceed to Phase 4 with warning, log low confidence
   - If user chooses "Stop" â†’ EXIT skill gracefully with success message

   **After retry from revise case:**
   - If coverage >= 50% â†’ proceed to Phase 4 (with warning if < 75%)
   - If coverage still < 50% â†’ EXIT gracefully with message:
     ```
     âŒ COVERAGE STILL TOO LOW

     After retry, coverage is still {X}% (< 50%).
     Refactoring not possible with these Context7 results.

     Options:
     - Accept current code quality
     - Try manual refactoring
     - Check if Context7 MCP is working correctly
     ```
     â†’ EXIT skill gracefully (no further retries to prevent infinite loop)

**Output (standard path):**
```
ğŸ“Š RELEVANCE EVALUATION

| Metric | Value |
|--------|-------|
| **Overall Coverage** | [X]% |
| **Overall Confidence** | [Y]% |

**Breakdown:**

| Category | Coverage | Confidence |
|----------|----------|------------|
| Security | [X]% | [Y]% |
| Performance | [X]% | [Y]% |
| Quality | [X]% | [Y]% |
| Error Handling | [X]% | [Y]% |

**Decision:** [proceed/unclear/additional_search/revise]
```

**Output (multi-perspective path - when score 50-85%):**
```
ğŸ“Š RELEVANCE EVALUATION (Multi-Perspective)

Initial Score: [X]% (unclear range - spawning evaluation agents)

**Agents spawned in parallel:**

| Agent | Score | Notes |
|-------|-------|-------|
| evaluate-optimist | [X]% | Usability score |
| evaluate-skeptic | [Y]% â†’ [100-Y]% | Gap â†’ Usability |
| evaluate-pragmatist | [Z]% | Actionability score |

| Metric | Value |
|--------|-------|
| **Weighted Final Score** | [W]% |
| **Calculation** | (optimistÃ—0.30) + (skeptic_usabilityÃ—0.30) + (pragmatistÃ—0.40) |

**Breakdown:**

| Category | Coverage | Confidence |
|----------|----------|------------|
| Security | [X]% | [Y]% |
| Performance | [X]% | [Y]% |
| Quality | [X]% | [Y]% |
| Error Handling | [X]% | [Y]% |

**Decision:** [proceed/proceed with warning/revise]
[If warning: Proceeding with low confidence - findings less certain]
```

---

### Phase 4: Create Refactor Plan (with Parallel Agents)

**Goal:** Systematically plan all improvements using Context7 insights, known vulnerability patterns, DRY analysis, and code analysis. Uses 3 parallel planning agents to provide different strategies for user choice.

**Steps:**

1. **Scan for known security patterns:**
   - Read `.claude/resources/5-refactor/references/security-patterns.md`
   - Scan loaded code files for each pattern:
     - Injection: `exec(`, `execSync(`, `os.system`, `eval(`, `new Function`
     - XSS: `.innerHTML =`, `dangerouslySetInnerHTML`, `document.write`
     - Deserialization: `pickle`
   - Check for `.github/workflows/*.yml` files â†’ scan for `${{ github.event.` in `run:` commands
   - Log all pattern matches found with file:line references

2. **Scan for DRY violations and refactoring opportunities:**
   - Read `.claude/resources/5-refactor/references/refactoring-patterns.md`
   - Scan loaded code files for:
     - **Duplicate code blocks** (>5 lines identical or near-identical)
     - **Similar logic patterns** (>70% similarity across locations)
     - **Repeated conditionals** (same if/else structure in multiple places)
     - **Copy-paste code** across different files
     - **Extract opportunities** (same code in 3+ locations)
   - For each finding, assess confidence (0-100%):
     - Exact duplicates: 90-95%
     - Similar patterns: 75-90%
     - Potential extractions: 80-90%
   - Log findings with:
     - Location 1 and Location 2 (file:line-line)
     - Number of duplicate lines
     - Similarity percentage
     - Suggested extraction (function/class/service name)

3. **Scan for over-engineering (code-simplifier patterns):**
   - Scan loaded code files for:
     - **Unnecessary abstractions**: Helper functions used only once
     - **Too many layers**: >3 levels of indirection for simple operations
     - **Premature optimization**: Complex caching/memoization for non-hot paths
     - **Over-defensive code**: Try/catch around code that can't fail
     - **Feature flag complexity**: Flags that could be direct code changes
     - **God objects**: Classes with >10 public methods or >500 lines
     - **Over-generic code**: Generic types/interfaces used in only 1 place
   - For each finding, assess:
     - Simplification opportunity (what can be removed/inlined)
     - Risk level (LOW = safe to inline, MED = needs testing, HIGH = core logic)
     - Lines that can be removed
   - Log findings with:
     - Location (file:line-line)
     - Pattern type (abstraction, layer, optimization, defensive, flag, god-object, generic)
     - Suggested simplification
     - Estimated lines removed

4. **Prepare agent context:**

   Compile the following for all planning agents:
   ```
   Feature: [name]
   Tech stack: [from CLAUDE.md]

   Research findings from FASE 2/3:
   - Security: [findings + coverage%]
   - Performance: [findings + coverage%]
   - Quality: [findings + coverage%]
   - Error Handling: [findings + coverage%]

   Code files to refactor:
   - [file list with contents]

   Pipeline files: [list of files belonging to this feature]

   Pattern scan results:
   - Security patterns found: [list with file:line]
   - DRY violations found: [list with locations]
   - Over-engineering found: [list with file:line and pattern type]

   Security patterns reference: [from .claude/resources/5-refactor/references/security-patterns.md]
   Refactoring patterns reference: [from .claude/resources/5-refactor/references/refactoring-patterns.md]
   ```

5. **Launch 3 planning agents in parallel (single message with 3 Task tool calls):**

   ```
   - Task(subagent_type="plan-conservative", prompt="[context above]
     Your mission: Create a CONSERVATIVE refactor plan (3-5 changes, LOW risk only).")

   - Task(subagent_type="plan-thorough", prompt="[context above]
     Your mission: Create a THOROUGH refactor plan (15-25 changes, all non-breaking).")

   - Task(subagent_type="plan-impact-focused", prompt="[context above]
     Your mission: Create an IMPACT-FOCUSED refactor plan (8-12 changes, best value/effort).")
   ```

6. **Wait for all 3 agents to complete:**
   - Each agent returns a structured plan with improvements
   - **Report progress as agents complete:**
     - Format: `Planning agents: {completed}/3 complete`
     - Show which agent just finished: `âœ“ plan-conservative complete (5 improvements)`

7. **Receive 3 plans with different scope/risk profiles:**

   | Plan | Philosophy | Typical Output |
   |------|------------|----------------|
   | **Conservative** | "First, do no harm" | 3-5 changes, LOW risk only |
   | **Thorough** | "Complete coverage" | 15-25 changes, all non-breaking |
   | **Impact-Focused** | "Maximum ROI" | 8-12 changes, best value/effort |

**Output:**
```
ğŸ“‹ 3 REFACTOR PLANS READY

**Pattern scan results:**

| Pattern | Count |
|---------|-------|
| Known vulnerabilities | [X matches] |
| DRY violations | [Y matches] |
| Over-engineering | [Z matches] |
| Files affected | [list] |

**Planning agents completed:**

| Agent | Improvements | Strategy |
|-------|--------------|----------|
| plan-conservative | [N] | LOW risk only |
| plan-thorough | [N] | complete coverage |
| plan-impact-focused | [N] | best ROI |

â†’ Ready for plan selection in Phase 4.5.
```

---

### Phase 4.5: Plan Selection & Approval

**Goal:** Present all 3 refactor plans to user for comparison and selection before modifying code.

**Steps:**

1. **Present plan comparison overview:**

   ```
   ğŸ“ REFACTOR PLANS - COMPARISON

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ ğŸ“Š 3 PLANS AVAILABLE                                                       â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚                                                                             â”‚
   â”‚  Plan              â”‚ Improvements â”‚ Risk Profile   â”‚ Effort    â”‚ When Best â”‚
   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
   â”‚ 1. CONSERVATIVE    â”‚ [3-5]        â”‚ LOW only       â”‚ [X] min   â”‚ Tight     â”‚
   â”‚    "Do no harm"    â”‚              â”‚                â”‚           â”‚ deadline  â”‚
   â”‚                    â”‚              â”‚                â”‚           â”‚           â”‚
   â”‚ 2. THOROUGH        â”‚ [15-25]      â”‚ LOW + MED      â”‚ [X] hr    â”‚ Full      â”‚
   â”‚    "Complete"      â”‚              â”‚                â”‚           â”‚ cleanup   â”‚
   â”‚                    â”‚              â”‚                â”‚           â”‚           â”‚
   â”‚ 3. IMPACT-FOCUSED  â”‚ [8-12]       â”‚ Best ROI       â”‚ [X] hr    â”‚ Balanced  â”‚
   â”‚    "Maximum ROI"   â”‚ (recommended)â”‚                â”‚           â”‚ approach  â”‚
   â”‚                    â”‚              â”‚                â”‚           â”‚           â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

   ğŸ“ˆ CATEGORY COVERAGE COMPARISON

   | Category        | Conservative | Thorough | Impact-Focused |
   |-----------------|--------------|----------|----------------|
   | Security        | [N]          | [N]      | [N]            |
   | Performance     | [N]          | [N]      | [N]            |
   | DRY/Refactoring | [N]          | [N]      | [N]            |
   | Simplification  | [N]          | [N]      | [N]            |
   | Quality         | [N]          | [N]      | [N]            |
   | Error Handling  | [N]          | [N]      | [N]            |
   | **TOTAL**       | [N]          | [N]      | [N]            |

   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

   ğŸ“‹ SCOPE ANALYSIS (per plan)

   | Scope           | Conservative | Thorough | Impact-Focused |
   |-----------------|--------------|----------|----------------|
   | Pipeline files  | [N]          | [N]      | [N]            |
   | External files  | [N] âš ï¸       | [N] âš ï¸   | [N] âš ï¸         |

   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

   ğŸ’¡ RECOMMENDATION: [Impact-Focused / Conservative / Thorough]
   [Brief reason for recommendation based on codebase analysis]
   ```

2. **Request plan selection:**

   **Send notification first:**
   ```bash
   powershell -ExecutionPolicy Bypass -File .claude/scripts/notify.ps1 -Title "Claude Code" -Message "Refactor plan ready"
   ```

   **Use AskUserQuestion tool:**
   - header: "Plan Selectie"
   - question: "Welk refactor plan wil je toepassen?"
   - options:
     - label: "Impact-Focused (Recommended)"
       description: "[8-12] verbeteringen, beste ROI, gebalanceerde aanpak"
     - label: "Conservative"
       description: "[3-5] verbeteringen, alleen LOW risk, quick wins"
     - label: "Thorough"
       description: "[15-25] verbeteringen, complete coverage, full cleanup"
     - label: "Bekijk details"
       description: "Bekijk alle verbeteringen van een specifiek plan"
     - label: "Custom selectie"
       description: "Kies specifieke verbeteringen uit alle plannen"
     - label: "Annuleren"
       description: "Stop refactor proces"
     - label: "Uitleg vraag"
       description: "Leg uit wat de verschillende plannen betekenen"
   - multiSelect: false

   **Handle "Uitleg vraag" response:**
   ```
   ğŸ“– PLAN TYPEN UITLEG

   **Conservative ("Do no harm")**: Minst riskant. Alleen verbeteringen
   met LOW risk die geen bestaande logica raken. Ideaal bij strakke
   deadlines of kritieke code.

   **Thorough ("Complete coverage")**: Meest uitgebreid. Alle non-breaking
   verbeteringen, inclusief LOW en MEDIUM risk. Ideaal voor volledige
   code cleanup.

   **Impact-Focused ("Maximum ROI")**: Beste balans. Verbeteringen met
   hoogste waarde per inspanning. Ideaal voor gebalanceerde aanpak.

   **Custom selectie**: Kies zelf welke specifieke verbeteringen je wilt
   toepassen uit alle drie de plannen.
   ```
   â†’ Return to plan selection

3. **Process user choice:**

   - **If "Impact-Focused"** â†’ use plan-impact-focused output, proceed to step 4
   - **If "Conservative"** â†’ use plan-conservative output, proceed to step 4
   - **If "Thorough"** â†’ use plan-thorough output, proceed to step 4
   - **If "Bekijk details"** â†’ show plan detail selection:

     **Use AskUserQuestion tool:**
     - header: "Plan Details"
     - question: "Welk plan wil je in detail bekijken?"
     - options:
       - label: "Conservative"
         description: "[3-5] verbeteringen, LOW risk only"
       - label: "Thorough"
         description: "[15-25] verbeteringen, complete coverage"
       - label: "Impact-Focused"
         description: "[8-12] verbeteringen, beste ROI"
     - multiSelect: false

     - Show full plan output from selected agent
     - Return to plan selection (max 3 iterations)

   - **If "Custom selectie"** â†’ show improvement selection with multiSelect:

     **Build improvement list from all plans:**
     - Collect all unique improvements from all 3 plans
     - Group by category (Security, Performance, DRY, Quality, Error Handling)
     - Deduplicate identical improvements

     **Use AskUserQuestion tool:**
     - header: "Custom Selectie"
     - question: "Welke verbeteringen wil je toepassen?"
     - options: (dynamically built from improvements)
       - For each improvement:
         - label: "[{category}] {file}:{line}" or "[{category}] {short description}"
         - description: "{issue} â†’ {fix} (Risk: {L/M/H}, Source: {plan})"
       - Always add last option:
         - label: "Uitleg vraag"
         - description: "Leg uit hoe custom selectie werkt"
     - multiSelect: true

     **Example options (dynamic):**
     ```
     options:
       - label: "[Security] src/auth.js:45", description: "SQL injection â†’ parameterized query (Risk: LOW, Source: Conservative)"
       - label: "[Performance] src/api.js:120", description: "N+1 query â†’ eager loading (Risk: MED, Source: Impact-Focused)"
       - label: "[DRY] src/utils.js:30-50", description: "Duplicate code â†’ extract function (Risk: LOW, Source: Thorough)"
       - label: "Uitleg vraag", description: "Leg uit hoe custom selectie werkt"
     ```

     **Handle "Uitleg vraag" response:**
     ```
     ğŸ“– CUSTOM SELECTIE UITLEG

     Je kunt hier specifieke verbeteringen kiezen uit alle drie plannen.
     Elke verbetering toont:
     - [Category]: Type verbetering (Security, Performance, etc.)
     - Locatie: Bestand en regelnummer
     - Issue â†’ Fix: Wat het probleem is en hoe het wordt opgelost
     - Risk: Risico niveau (LOW/MED/HIGH)
     - Source: Uit welk plan de verbetering komt

     Selecteer alle verbeteringen die je wilt toepassen en bevestig.
     ```
     â†’ Return to custom selection

     - Build custom plan from selected improvements
     - Proceed to step 4 with custom selection

   - **If "Annuleren"** â†’ EXIT skill gracefully with message "Refactor geannuleerd door gebruiker"

4. **Show selected plan detail and confirm:**

   After plan selection, show the detailed preview of the selected plan:

   ```
   ğŸ“ SELECTED PLAN: [CONSERVATIVE / THOROUGH / IMPACT-FOCUSED / CUSTOM]

   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

   Impact Summary:
   ğŸ”´ HIGH priority: [X] improvements (security vulnerabilities)
   ğŸŸ¡ MEDIUM priority: [Y] improvements (performance + DRY + error handling)
   ğŸŸ¢ LOW priority: [Z] improvements (code quality)

   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

   ğŸ”´ SECURITY IMPROVEMENTS ([X])

   1. {file}:{line} [PIPELINE]
      Issue: [description]
      Fix: [solution]
      Result: [what this prevents/achieves]
      Effort: [SMALL/MEDIUM/LARGE]    Risk: [LOW/MEDIUM/HIGH]

      Before:
      ```{lang}
      [code snippet]
      ```

      After:
      ```{lang}
      [code snippet]
      ```

   [... continue for all categories with before/after snippets ...]

   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

   âœ… POSITIVE OBSERVATIONS

   What's done well in the codebase:
   - [Positive observation 1]
   - [Positive observation 2]
   - [Positive observation 3]

   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

   Files to be modified: [count]
   - {file1} ([N] changes) [PIPELINE]
   - {file2} ([M] changes) [EXTERNAL] âš ï¸

   Rollback available: YES (automatic on test failure)
   ```

5. **Final confirmation:**

   **Use AskUserQuestion tool:**
   - header: "Bevestiging"
   - question: "Wil je dit plan toepassen? ([N] wijzigingen)"
   - options:
     - label: "Ja, pas alles toe (Recommended)"
       description: "Pas alle [N] wijzigingen toe uit het geselecteerde plan"
     - label: "Alleen pipeline bestanden"
       description: "Excludeer [Y] externe bestandswijzigingen, alleen feature bestanden"
     - label: "Selecteer specifieke verbeteringen"
       description: "Kies welke verbeteringen je wilt toepassen"
     - label: "Terug naar plan selectie"
       description: "Kies een ander plan"
     - label: "Annuleren"
       description: "Stop refactor proces"
     - label: "Uitleg vraag"
       description: "Leg uit wat de opties betekenen"
   - multiSelect: false

   **Handle "Uitleg vraag" response:**
   ```
   ğŸ“– BEVESTIGING OPTIES UITLEG

   **Ja, pas alles toe**: Past alle verbeteringen uit het geselecteerde
   plan toe. Dit is de aanbevolen optie voor complete refactoring.

   **Alleen pipeline bestanden**: Past alleen verbeteringen toe in
   bestanden die bij deze feature horen (aangemaakt door /2-code).
   Externe bestanden worden overgeslagen.

   **Selecteer specifieke verbeteringen**: Laat je kiezen welke
   individuele verbeteringen je wilt toepassen.

   **Terug naar plan selectie**: Ga terug om een ander plan te kiezen
   (Conservative, Thorough, of Impact-Focused).

   **Annuleren**: Stop het refactor proces zonder wijzigingen.
   ```
   â†’ Return to confirmation

6. **Process final confirmation:**

   - **If "Ja, pas alles toe"** â†’ proceed to Phase 5 with full selected plan

   - **If "Alleen pipeline bestanden"** â†’ filter to `[PIPELINE]` improvements, proceed to Phase 5

   - **If "Selecteer specifieke verbeteringen"** â†’ show improvement selection with multiSelect:

     **Use AskUserQuestion tool:**
     - header: "Verbeteringen Selectie"
     - question: "Welke verbeteringen wil je toepassen?"
     - options: (dynamically built from plan improvements)
       - For each improvement in selected plan:
         - label: "[{priority}] {file}:{line}"
         - description: "{issue} â†’ {fix} (Effort: {S/M/L}, Risk: {L/M/H}) [{PIPELINE/EXTERNAL}]"
       - Always add last option:
         - label: "Uitleg vraag"
         - description: "Leg uit hoe specifieke selectie werkt"
     - multiSelect: true

     **Example options (dynamic):**
     ```
     options:
       - label: "[HIGH] src/auth.js:45", description: "SQL injection â†’ parameterized query (Effort: S, Risk: LOW) [PIPELINE]"
       - label: "[MED] src/api.js:120", description: "N+1 query â†’ eager loading (Effort: M, Risk: MED) [PIPELINE]"
       - label: "[LOW] src/utils.js:30", description: "Magic number â†’ named constant (Effort: S, Risk: LOW) [EXTERNAL]"
       - label: "Uitleg vraag", description: "Leg uit hoe specifieke selectie werkt"
     ```

     **Handle "Uitleg vraag" response:**
     ```
     ğŸ“– SPECIFIEKE SELECTIE UITLEG

     Je kunt hier individuele verbeteringen kiezen uit het plan.
     Elke verbetering toont:
     - [Priority]: HIGH (security), MED (performance/DRY/error), LOW (quality)
     - Locatie: Bestand en regelnummer
     - Issue â†’ Fix: Wat het probleem is en hoe het wordt opgelost
     - Effort: Inspanning (S=klein, M=medium, L=groot)
     - Risk: Risico (LOW/MED/HIGH)
     - [PIPELINE/EXTERNAL]: Of het bestand bij de feature hoort

     Selecteer alle verbeteringen die je wilt toepassen.
     ```
     â†’ Return to improvement selection

     - Build filtered plan from selected improvements
     - Proceed to Phase 5 with filtered selection

   - **If "Terug naar plan selectie"** â†’ return to step 2 (plan selection)

   - **If "Annuleren"** â†’ EXIT skill gracefully with message "Refactor geannuleerd door gebruiker"

   **Scope label rules:**
   - `[PIPELINE]` = file is in `pipeline_files` list (from Phase 1 step 6)
   - `[EXTERNAL] âš ï¸` = file is NOT in `pipeline_files` list

   **Effort indicator:**
   - `[SMALL]` = 1-10 lines changed, simple modification
   - `[MEDIUM]` = 10-30 lines changed, multiple adjustments
   - `[LARGE]` = 30+ lines changed, significant refactor

   **Risk indicator:**
   - `[LOW]` = purely additive (validation, logging), no existing logic touched
   - `[MEDIUM]` = existing code modified but flow remains the same
   - `[HIGH]` = core logic/flow modified

**Output:**
```
âœ… PLAN APPROVED

| Field | Value |
|-------|-------|
| **Selected plan** | [CONSERVATIVE / THOROUGH / IMPACT-FOCUSED / CUSTOM] |
| **Pipeline files** | [X] |
| **External files** | [Y] |
| **Changes to apply** | [count] |

â†’ Proceeding to apply changes...
```

---

### Phase 5: Apply Improvements

**Goal:** Execute the refactor plan by modifying code files.

**Priority Order (execute in this sequence):**

1. **Security improvements** (apply first)
2. **Performance optimizations** (apply second)
3. **DRY/Refactoring improvements** (apply third)
4. **Simplification improvements** (apply fourth - removes over-engineering)
5. **Code quality improvements** (apply fifth)
6. **Error handling improvements** (apply last)

**Steps:**

0. **Initialize change tracking (before any edits):**
   ```
   tracking = {
     "git_hash_before": <run: git rev-parse HEAD>,
     "modified_files": [],
     "changes_by_category": {
       "security": [],
       "performance": [],
       "dry": [],
       "simplification": [],
       "quality": [],
       "error_handling": []
     }
   }
   ```
   - Store current git hash for potential rollback
   - Initialize empty tracking structure

1. **For each planned improvement:**
   - Use Edit tool to modify code files
   - Apply all changes in priority order (Security â†’ Performance â†’ DRY â†’ Simplification â†’ Quality â†’ Error Handling)
   - Keep changes non-breaking
   - Add comments where complexity increases
   - **After each edit, update tracking:**
     - Append file path to `modified_files` (if not already present)
     - Append change details to appropriate category in `changes_by_category`
   - **Report progress after each category:**
     - Format: `âœ“ Applied {count} {category} improvements ({current_category}/6 categories)`

2. **Track all changes:**
   - List of modified files (from `tracking.modified_files`)
   - What changed per file (from `tracking.changes_by_category`)
   - Rationale per change
   - **This tracking is required for Phase 6 rollback and Phase 7 documentation**

**Non-breaking rule:**
- Only make changes that preserve existing behavior
- No API changes
- No database schema changes
- No breaking parameter changes

**Output:**
```
âœ… IMPROVEMENTS APPLIED

**Modified files:** [list]

**Changes by category:**

| Category | Count |
|----------|-------|
| Security fixes | [count] |
| Performance optimizations | [count] |
| DRY/Refactoring | [count] |
| Simplification | [count] |
| Quality | [count] |
| Error handling | [count] |

â†’ Ready for test verification.
```

---

### Phase 6: Test Verification

**Goal:** Verify all tests still pass after refactoring. Rollback if tests fail.

**Steps:**

1. **Run test suite:**
   ```bash
   # Detect and run project's test framework
   ./vendor/bin/pest  # Laravel example
   npm test           # Node.js example
   pytest             # Python example
   ```

2. **Evaluate results:**
   - All tests pass â†’ Proceed to Phase 7 (Documentation)
   - Any test fails â†’ Execute rollback

3. **If tests fail - Immediate Rollback:**

   **Primary rollback method:**
   ```bash
   # Revert all changes made in Phase 5
   git checkout -- [modified files]
   ```

   **If git checkout fails - Fallback to hard reset:**
   ```bash
   # Use saved git hash from Phase 5 tracking
   git reset --hard {tracking.git_hash_before}
   ```

   **If both methods fail - Manual recovery:**
   ```
   âš ï¸ ROLLBACK FAILED - MANUAL INTERVENTION REQUIRED

   Both git checkout and git reset failed.

   Manual recovery steps:
   1. Check git status: git status
   2. Stash any uncommitted changes: git stash
   3. Hard reset to safe state: git reset --hard {tracking.git_hash_before}
   4. If still broken: git reflog (find last good state)

   Git hash before changes: {tracking.git_hash_before}
   Modified files: [list from tracking.modified_files]
   ```
   â†’ **STOP** - do not proceed, await manual recovery

   - Report which tests failed
   - Report why rollback occurred
   - Suggest smaller scope refactor or accepting current quality
   - **STOP** - do not proceed to Phase 7

**Output (if tests pass):**
```
âœ… TEST VERIFICATION PASSED

| Metric | Value |
|--------|-------|
| **Tests** | [X/X] passing |

â†’ Ready for documentation.
```

**Output (if tests fail - rollback successful):**
```
âŒ TEST VERIFICATION FAILED

| Field | Value |
|-------|-------|
| **Failed tests** | [list] |
| **Rollback executed** | âœ“ |
| **Changes reverted** | âœ“ |
| **Git hash restored** | {tracking.git_hash_before} |

**Refactor attempt unsuccessful. Options:**
1. Try smaller scope refactor (fewer changes)
2. Accept current code quality
3. Investigate test failures manually
```

**Output (if rollback fails):**
```
âš ï¸ CRITICAL: ROLLBACK FAILED

| Field | Value |
|-------|-------|
| **Failed tests** | [list] |
| **git checkout** | FAILED |
| **git reset --hard** | FAILED |
| **Git hash before** | {tracking.git_hash_before} |
| **Modified files** | [list] |

**MANUAL INTERVENTION REQUIRED** (see steps above)
```

---

### Phase 7: Documentation

**Goal:** Save refactor results to feature folder with timestamp.

**Steps:**

1. **Get current timestamp:**
   ```
   Use mcp__time__get_current_time with timezone "Europe/Amsterdam"
   ```

2. **Execute generate_refactor_log.py:**
   ```bash
   python3 scripts/generate_refactor_log.py \
     --feature {feature-name} \
     --timestamp "[from time MCP]" \
     --security-improvements "[list]" \
     --performance-improvements "[list]" \
     --quality-improvements "[list]" \
     --error-handling-improvements "[list]" \
     --modified-files "[list]" \
     --scope-summary "pipeline:[X],external:[Y]" \
     --output {refactor-output-path}
   ```

   **Output path depends on mode:**
   - Normal: `.workspace/features/{name}/05-refactor.md`
   - Part: Append "## Part: {NN}-{name}" section to `.workspace/features/{feature}/05-refactor.md`
   - Extend/Change: Append section to `.workspace/features/{parent}/05-refactor.md`

3. **Script generates structured markdown:**
   ```markdown
   # Refactor Log - {Feature/Part Name}
   Generated: [timestamp]

   ## User Summary

   ### What Was Refactored
   - [High-level description of improvements made]

   ### Key Decisions Made
   - [Decision 1]: [rationale]
   - [Decision 2]: [rationale]

   ### Positive Observations
   What was already done well:
   - [Positive observation 1]
   - [Positive observation 2]

   ### Suggested Next Steps
   - [If applicable, what could be improved in future iterations]

   ---

   ## Technical Details

   ### Scope Summary
   - Pipeline files modified: [X]
   - External files modified: [Y]

   ### Security Improvements
   - [file:line] - [issue] â†’ [fix] â†’ [result] - Effort: [S/M/L] Risk: [L/M/H] [PIPELINE/EXTERNAL]

   ### Performance Improvements
   - [file:line] - [issue] â†’ [fix] â†’ [result] - Effort: [S/M/L] Risk: [L/M/H] [PIPELINE/EXTERNAL]

   ### DRY/Refactoring Improvements
   - [file:line] â†” [file:line] - [extraction] â†’ [result] - Effort: [S/M/L] Risk: [L/M/H] [PIPELINE/EXTERNAL]

   ### Simplification Improvements
   - [file:line] - [over-engineering removed] â†’ [simplified to] â†’ [lines removed] - Effort: [S/M/L] Risk: [L/M/H] [PIPELINE/EXTERNAL]

   ### Code Quality Improvements
   - [file:line] - [issue] â†’ [fix] â†’ [result] - Effort: [S/M/L] Risk: [L/M/H] [PIPELINE/EXTERNAL]

   ### Error Handling Improvements
   - [file:line] - [issue] â†’ [fix] â†’ [result] - Effort: [S/M/L] Risk: [L/M/H] [PIPELINE/EXTERNAL]

   ### Modified Files
   - [list with descriptions]

   ## Production Ready
   Status: YES
   ```

4. **Save to correct location:**
   - Location determined from detected mode (see step 2)

5. **Execute `update_docs.py` to update project documentation:**
   ```bash
   python3 .claude/resources/2-code/scripts/update_docs.py
   ```

   - Reads project type from CLAUDE.md
   - Runs enabled documentation generators
   - Updates: docs/api.md, docs/components.mmd, docs/events.mmd, etc.
   - Ensures documentation reflects refactored code

6. **Update feature overview (00-overview.md):**
   - Read `.workspace/features/{name}/00-overview.md` (if exists)
   - Update the following sections:

   **A. Update Status table:**

   ```markdown
   ## Status

   | Pipeline | Requirements | Updated |
   |----------|--------------|---------|
   | `REFACTORED` | {X}/{Y} | {date} |
   ```

   **B. Append to History:**

   ```markdown
   ## History

   | Date | Phase | Summary |
   |------|-------|---------|
   | {date} | Refactor | {summary} |
   ```

**Output:**
```
ğŸ“‹ DOCUMENTATION COMPLETE

| Document | Status |
|----------|--------|
| Refactor log | {refactor-output-path} âœ“ |
| Feature overview | {path}/00-overview.md âœ“ [Technical notes updated] |
| Timestamp | [from time MCP] |

**update_docs.py results:**

| Script | Output | Status |
|--------|--------|--------|
| update_erd.py | docs/erd.mmd | âœ“ |
| update_api_docs.py | docs/api.md | âœ“ |
| update_components.py | docs/components.mmd | âœ“ |
| update_events.py | docs/events.mmd | âœ“ |

âœ… REFACTOR COMPLETE - READY FOR MANUAL REVIEW
```

**Send notification:**
```bash
powershell -ExecutionPolicy Bypass -File .claude/scripts/notify.ps1 -Title "Claude Code" -Message "Refactor complete"
```

**Auto-commit changes:**
```bash
git add .
git commit -m "$(cat <<'EOF'
refactor({name}): {summary}

{description}
EOF
)"
```

**Commit message format:**
- `{name}`: Feature name
- `{summary}`: One-line summary (e.g., "Security and performance improvements")
- `{description}`: 2-3 lines describing what was refactored:
  - Categories improved (security, performance, quality, error handling)
  - Number of improvements applied
  - Scope (pipeline files, external files)

**IMPORTANT:** Do NOT add Co-Authored-By, ğŸ¤– Generated with Claude Code, or any other footer to pipeline commits.

7. **Show completion message:**

   After successful refactor, display:

   ```text
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   âœ… PIPELINE COMPLETE

   Feature {feature-name} has completed all phases:
   âœ“ /1-plan - Planning
   âœ“ /2-code - Implementation
   âœ“ /3-verify - Verification
   âœ“ /4-refine - Refinement (if used)
   âœ“ /5-refactor - Refactoring

   Ready for production! ğŸš€
   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   ```

---

## Best Practices

### Language
Follow the Language Policy in CLAUDE.md.

### Notifications
- **Notify when Claude waits for user input AFTER a long-running phase**
- Notification moments:
  - Phase 4.5 (after Phase 2-4 research/planning): "Refactor plan ready"
  - After Phase 7 (workflow complete): "Refactor complete"
- Use the shared script: `.claude/scripts/notify.ps1` with `-Title` and `-Message` parameters
- Never skip notifications - user may be away from screen during agent execution

### Workflow Execution
- Execute all eight phases sequentially (including Phase 4.5 preview/approval)
- Never skip Phase 4.5 - user must approve changes before code modification
- Stop immediately if tests fail in Phase 6
- Always rollback on test failure - no exceptions
- Use sequential-thinking for Phase 3 (evaluation) and Phase 4 (planning)
- Keep refactoring scope reasonable - prefer smaller, safer changes

### Validation First
- Always validate .workspace/features/ exists before proceeding
- Always validate context and implementation files exist before reading
- Report clear error messages with actionable next steps
- Exit gracefully on validation failures - never crash with technical errors

### Context7 Research Strategy
- Always research in priority order: Security â†’ Performance â†’ Quality â†’ Error Handling
- Spawn 4 specialized agents in parallel using Task tool
- Each agent autonomously plans and executes Context7 research
- Focus on framework-specific patterns from intent/research stack info
- Extract actionable insights, not theoretical concepts
- Document relevance scores for transparency

### Relevance Evaluation Discipline
- Always use sequential-thinking to score each category
- Be honest with scoring - low scores indicate need for more research
- If coverage < 75%, execute additional targeted searches
- Max 1 retry cycle to prevent infinite loops
- Proceed only when confident in research quality

### Planning with Sequential Thinking
- Map Context7 insights to specific code locations (file:line)
- Validate each change is non-breaking before adding to plan
- Prioritize security fixes above all else
- Performance optimizations second priority
- Quality improvements third priority
- Error handling improvements last priority

### Non-Breaking Changes Only
- No API signature changes
- No database schema modifications
- No breaking parameter changes
- No removal of public methods/functions
- Preserve all existing behavior
- If breaking change needed â†’ exit and suggest new /1-plan cycle

### Incremental Application
- Apply all approved changes in Phase 5 in priority order: Security â†’ Performance â†’ Quality â†’ Error Handling
- Run tests once in Phase 6 after all changes are applied (default workflow)
- For high-risk refactors, consider running tests after each category (optional advanced mode)
- Stop immediately if any test fails and rollback ALL changes

### Test Verification Discipline
- Always run full test suite after applying changes
- Never skip test verification
- Immediate rollback on any test failure
- Report which tests failed and why
- No manual fixes during refactor - clean rollback only

### Documentation Quality
- Always use time MCP for accurate timestamps
- List all modified files with descriptions
- Document rationale for each category of changes
- Include Context7 coverage scores for transparency
- Update 00-overview.md with technical notes (security/performance improvements)
- Save to correct location based on mode:
  - Normal: `.workspace/features/{name}/05-refactor.md`
  - Part: Append section to `.workspace/features/{feature}/05-refactor.md` (parts are sections, not folders)
  - Extend/Change: Append section to `.workspace/features/{parent}/05-refactor.md`

### Communication
- Clear phase transitions
- Report progress at each phase
- Transparent about coverage scores
- Immediate error reporting
- Actionable recommendations if rollback occurs

## Error Handling

### Feature Selection Failures

**Problem:** No features found in .workspace/features/
- **Cause:** /1-plan and /2-code not run yet
- **Action:** Inform user to run /1-plan then /2-code first
- **Fallback:** Exit gracefully

**Problem:** Selected feature has no context files (01-intent.md, 01-research.md) or implementation file (02-implementation.md)
- **Cause:** Incomplete feature pipeline execution
- **Action:** Report missing files
- **Fallback:** Ask user which files to use or exit

### Context7 Research Failures

**Problem:** Context7 search returns low relevance (< 50%)
- **Cause:** Generic queries or uncommon stack
- **Action:** Try alternative search terms (broader or more specific)
- **Fallback:** Proceed with lower confidence, inform user in output

**Problem:** Context7 MCP unavailable
- **Cause:** MCP server not running
- **Action:** Report error, cannot proceed without research
- **Fallback:** Exit and ask user to start MCP server

### Coverage Evaluation Failures

**Problem:** evaluate_refactor_coverage.py script fails
- **Cause:** Script error or invalid input
- **Action:** Manually calculate coverage from sequential-thinking scores
- **Fallback:** Use judgment to proceed if scores reasonable

**Problem:** Overall coverage < 50% after retry
- **Cause:** Insufficient Context7 results
- **Action:** Report low coverage to user
- **Fallback:** Ask user to proceed anyway or exit

### Planning Failures

**Problem:** Sequential-thinking loops or gets stuck
- **Cause:** Complex codebase or unclear requirements
- **Action:** Break down problem into smaller chunks
- **Fallback:** Report to user and ask for guidance

**Problem:** No improvements identified
- **Cause:** Code already high quality or out of scope
- **Action:** Report that no refactoring needed
- **Fallback:** Exit gracefully with success message

### Code Modification Failures

**Problem:** Cannot modify file (Edit tool fails)
- **Cause:** File locked, permissions, or doesn't exist
- **Action:** Skip that specific change
- **Fallback:** Continue with other changes, report skipped files

**Problem:** Syntax error introduced during edit
- **Cause:** Edit mistake or complex refactoring
- **Action:** Immediate rollback before test phase
- **Fallback:** Report error and exit

### Test Verification Failures

**Problem:** Tests fail after refactoring
- **Cause:** Breaking change introduced
- **Action:** Immediate rollback (git checkout or revert edits)
- **Next:** Report failure, suggest smaller scope

**Problem:** Test framework not detected
- **Cause:** Unusual test setup
- **Action:** Ask user which command to run
- **Fallback:** Skip test verification with warning (not recommended)

**Problem:** Tests hang or timeout
- **Cause:** Infinite loop or resource issue
- **Action:** Kill test process
- **Fallback:** Rollback changes

### Documentation Failures

**Problem:** generate_refactor_log.py fails
- **Cause:** Script error or missing parameters
- **Action:** Manually create 05-refactor.md with template
- **Fallback:** Continue but flag manual documentation needed

**Problem:** time MCP fails
- **Cause:** MCP server unavailable
- **Action:** Use fallback timestamp format or ask user
- **Fallback:** Continue with estimated time

**Problem:** Cannot write to .workspace/features/{name}/
- **Cause:** Permissions or path doesn't exist
- **Action:** Create directory if missing
- **Fallback:** Report error and suggest manual save

### Recovery Strategy

When errors occur:
1. Report clear error with context
2. Attempt automatic recovery
3. Fall back to manual alternative
4. Rollback on critical failures (test failures)
5. Never leave code in broken state
6. Always inform user of recovery actions taken

## Restrictions

This skill must NEVER:
- Skip loading all documentation files in feature folder
- Proceed without existing 02-implementation.md
- Make breaking changes (API changes, schema modifications)
- Skip user approval at Phase 4.5
- Skip test verification in Phase 6
- Proceed if tests fail (must rollback)
- **Skip reading existing files** (00-overview.md, 03-verify.md, 04-refine.md) when present in feature folder
- **Ignore previous refinement context** when planning refactoring
- **Create part subfolders** (parts are sections within parent files, not separate folders)
- **Skip spawning 3 evaluation agents in Phase 3** when score is 50-85% (evaluate-optimist, evaluate-skeptic, evaluate-pragmatist)
- **Skip spawning 3 planning agents in Phase 4** (plan-conservative, plan-thorough, plan-impact-focused)
- **Apply refactor plan without user selection** from the 3 options in Phase 4.5

This skill must ALWAYS:
- **Load ALL files in feature folder** (all .md files for complete context)
- **Detect part/extend/change via sections in 01-intent.md** (not separate folders)
- Validate .workspace/features/ exists before proceeding
- Validate context and implementation files exist
- Spawn 4 research agents in parallel (security, performance, quality, error-handling)
- Evaluate research relevance before planning
- **Spawn 3 evaluation agents in parallel when score 50-85%** (Phase 3)
- **Calculate weighted score from 3 evaluation agents** (optimistÃ—0.30 + skepticÃ—0.30 + pragmatistÃ—0.40)
- **Spawn 3 planning agents in parallel** (Phase 4)
- **Present plan comparison table and wait for user selection** (Phase 4.5)
- Wait for user approval at Phase 4.5 before modifying code
- Run full test suite after applying changes
- Rollback immediately on any test failure
- **Save output to correct location based on mode:**
  - Normal: `.workspace/features/{name}/05-refactor.md`
  - Part: Append "## Part:" section to `.workspace/features/{feature}/05-refactor.md`
  - Extend/Change: Append section to `.workspace/features/{parent}/05-refactor.md`
- Update 00-overview.md with technical notes (if file exists)
- Execute update_docs.py to update project documentation
- Send notifications after planning and completion