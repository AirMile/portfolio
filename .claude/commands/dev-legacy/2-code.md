---
description: Guides Claude Code through rapid implementation with architecture patterns, testing, and documentation
---

# Code Implementation Skill

## Overview

This skill guides Claude Code through rapid feature implementation with a "make it work first" philosophy. It loads context from `.workspace/features/` files (generated by /1-plan skill), then focuses on functional code with clean architecture patterns, automated testing, and comprehensive documentation updates. The skill operates in five automatic phases: preparation, implementation, testing, documentation, and completion.

The skill is universal for backend, frontend, and full-stack web/app projects, maintaining clean separation between configuration, controllers, and components using central config patterns.

**Trigger**: `/2-code` command

## When to Use

This skill activates when:

**Trigger:**
- `/2-code` command in Claude Code

**NOT for:**
- Code review and refinement (use /4-refine)
- Deep security audits (use /4-refine)
- Style guide enforcement (use /4-refine)
- Architecture redesigns (use /analyze first)
- Game projects (use game-specific architecture patterns)

## Workflow

The skill operates through five automatic phases. Execute each phase sequentially without user intervention unless errors occur.

### FASE 0: FEATURE SELECTION

**Goal:** Let user select which feature to implement from available features.

**Steps:**

1. **Check if feature name provided with command:**

   **If user ran `/2-code {feature-name}`:**
   - Skip numbered list
   - Use provided feature name directly
   - Validate it exists in `.workspace/features/{feature-name}/01-intent.md`
   - If valid: proceed to step 4 (confirm selection)
   - If invalid: show error, then fall back to numbered list (step 2)

   **If user ran `/2-code` without arguments:**
   - Proceed to step 2 (show numbered list)

2. **List available features (only if no feature name provided):**
   - Scan `.workspace/features/` for all folders with `01-intent.md`
   - For each feature, check if `.worktree` file exists and read worktree path
   - Show numbered list with feature status AND worktree info

   ```
   ğŸ“‹ AVAILABLE FEATURES:

   | # | Feature | Worktree | Status | Parts/Extends/Changes |
   |---|---------|----------|--------|----------------------|
   | 1 | checkout | ../project--checkout | Ready | 3 parts (01-cart, 02-payment, 03-ui) |
   | 2 | user-profile | ../project--user-profile | Ready | - |
   | 3 | notifications | (no worktree) | Ready | 1 extend (email-templates) |

   ```

   **Worktree column logic:**
   - If `.workspace/features/{name}/.worktree` exists â†’ show worktree path
   - If no `.worktree` file â†’ show "(no worktree)"

   Use AskUserQuestion tool:
   - header: "Feature Selectie"
   - question: "Welke feature wil je implementeren?"
   - options:
     - For each feature in the list, create an option:
       - label: "{feature-name} (Recommended)" for first/most relevant
       - description: "Status: {status}, {parts info}"
     - label: "Uitleg", description: "Leg uit wat deze stap betekent"
   - multiSelect: false

   Response handling:
   - Map selected option to feature name â†’ proceed to step 4
   - If invalid: show error and re-prompt

3. **Handle user selection:**
   - Selected feature from modal â†’ proceed to step 4
   - If invalid: show error and re-prompt

4. **Auto-detect part/extend/change (always runs after feature selection):**

   **If feature has NO parts/extends/changes:** Skip to step 5

   **If feature HAS parts/extends/changes:**
   - Read `01-intent.md` to find all sections (`## Part: {name}`, `## Extend: {name}` or `## Change: {name}`)
   - For each section, check status in `02-implementation.md`:
     - If section exists with code files â†’ `âœ“ Implemented`
     - If section missing or empty â†’ `â—‹ Pending`
   - **Auto-select** the first pending part/extend/change

   ```
   ğŸ“‹ AUTO-DETECTED SECTION

   Feature: checkout
   Sections: 3 total (1 implemented, 2 pending)

   | # | Name | Type | Status |
   |---|------|------|--------|
   | 1 | 01-cart-models | Part | âœ“ Implemented |
   | 2 | 02-payment-backend | Part | â—‹ Pending â† NEXT |
   | 3 | 03-checkout-ui | Part | â—‹ Pending |

   Auto-selected: 02-payment-backend (part)
   ```

   **If all sections implemented:**
   ```
   âœ… ALL SECTIONS IMPLEMENTED

   Feature: checkout
   All parts/extends/changes are already implemented.

   Options:
   - Run /3-verify {feature-name} to verify
   - Run /4-refine {feature-name} to make changes
   ```
   â†’ EXIT skill gracefully

5. **Confirm selection:**
   ```
   âœ… SELECTED: {feature-name} {part/extend/change if applicable}

   Checking worktree...
   ```

6. **Verify correct worktree (if .worktree file exists):**

   **Skip if:** task_type is EXTEND or CHANGE (these use parent feature's worktree)

   **Steps:**

   a. **Check for .worktree file:**
      ```bash
      cat .workspace/features/{feature-name}/.worktree
      ```
      - If file exists â†’ read worktree path
      - If file doesn't exist â†’ continue without worktree (legacy mode)

   b. **Compare current directory with worktree path:**
      ```bash
      # Get current directory (absolute path)
      pwd
      ```
      - If current directory matches worktree path â†’ continue to FASE 1
      - If current directory does NOT match â†’ prompt user to switch

   c. **If NOT in correct worktree:**
      ```
      âš ï¸ WRONG WORKTREE

      Feature "{feature-name}" has a dedicated worktree:
      {worktree-path}

      You are currently in:
      {current-directory}
      ```

      Use AskUserQuestion tool:
      - header: "Worktree"
      - question: "Je zit niet in de juiste worktree. Wat wil je doen?"
      - options:
        - label: "Open worktree (Recommended)"
          description: "Open {worktree-path} in nieuw VSCode venster"
        - label: "Toch hier doorgaan"
          description: "Werk in huidige directory (niet aanbevolen)"
        - label: "Annuleren"
          description: "Stop en switch handmatig"
        - label: "Uitleg"
          description: "Leg uit wat worktrees zijn"
      - multiSelect: false

      **If "Open worktree":**
      ```bash
      code "{worktree-path}"
      ```
      Report:
      ```
      ğŸ“‚ WORKTREE OPENED

      VSCode venster geopend voor: {worktree-path}

      Switch naar dat venster en run /2-code {feature-name} opnieuw.
      ```
      â†’ EXIT skill (user continues in other window)

      **If "Toch hier doorgaan":**
      Report:
      ```
      âš ï¸ Continuing in current directory (worktree ignored)
      ```
      â†’ Continue to FASE 1 (with warning logged)

      **If "Annuleren":**
      â†’ EXIT skill gracefully

   d. **If IN correct worktree (or no worktree defined):**
      ```
      âœ… WORKTREE VERIFIED

      Working in: {current-directory}
      Feature: {feature-name}

      â†’ Loading context...
      ```

**Output:**

```text
âœ… FEATURE SELECTED

Feature: {name}
[If part:] Part: {part-name}
[If extend:] Extend: {extend-name}
[If change:] Change: {change-name}
Worktree: {worktree-path} (verified)

â†’ Loading context...
```

---

### FASE 1: PREPARATION

**Goal:** Load context and understand project structure before implementation.

**Steps:**

1. **Use selected feature from FASE 0:**
   - Feature name and optional part already determined
   - Skip manual input - proceed directly to validation

2. **Sanitize user input (BEFORE validation):**
   - Trim leading/trailing whitespace
   - Normalize path separators to `/`
   - Convert to lowercase for consistent matching

   **Note:** Sanitization happens FIRST to ensure validation checks clean input.

3. **Validate sanitized input:**
   - If input is empty after sanitization:
     ```
     âŒ Empty input. Please provide a feature name or path.
     ```

     Use AskUserQuestion tool:
     - header: "Feature Input Required"
     - question: "No feature name provided. What do you want to implement?"
     - options:
       - label: "List available features (Recommended)", description: "Show all features in .workspace/features/"
       - label: "Enter feature name", description: "Type a specific feature name"
       - label: "Explain question", description: "Explain what this means"
     - multiSelect: false

     Response handling:
     - If "List available features": scan .workspace/features/ and show numbered list
     - If "Enter feature name": wait for user to type feature name

   - If input contains path traversal (`../`, `..\\`, or absolute paths like `C:\` or `/root`):
     ```
     âŒ Invalid path. Path must be within .workspace/features/
     ```

     Use AskUserQuestion tool:
     - header: "Invalid Path"
     - question: "The path contains traversal characters. How do you want to proceed?"
     - options:
       - label: "List available features (Recommended)", description: "Show all features in .workspace/features/"
       - label: "Enter different path", description: "Type a valid relative path"
       - label: "Explain question", description: "Explain what this means"
     - multiSelect: false

     Response handling:
     - If "List available features": scan .workspace/features/ and show numbered list
     - If "Enter different path": wait for user to type valid path

   - If input contains special characters (`<`, `>`, `|`, `*`, `?`, `;`, `` ` ``, `$`, `&`, `(`, `)`, `{`, `}`, `[`, `]`, `'`, `"`):
     ```
     âŒ Invalid characters in path. Use only alphanumeric, dash, underscore, and forward slash.
     ```

     Use AskUserQuestion tool:
     - header: "Invalid Characters"
     - question: "The path contains special characters. How do you want to proceed?"
     - options:
       - label: "List available features (Recommended)", description: "Show all features in .workspace/features/"
       - label: "Enter corrected path", description: "Type a path without special characters"
       - label: "Explain question", description: "Explain what this means"
     - multiSelect: false

     Response handling:
     - If "List available features": scan .workspace/features/ and show numbered list
     - If "Enter corrected path": wait for user to type valid path

   - If input length > 200 characters:
     ```
     âŒ Path too long (max 200 characters). Use a shorter feature name.
     ```

     Use AskUserQuestion tool:
     - header: "Path Too Long"
     - question: "The path exceeds 200 characters. How do you want to proceed?"
     - options:
       - label: "List available features (Recommended)", description: "Show all features in .workspace/features/"
       - label: "Enter shorter path", description: "Type a shorter feature name"
       - label: "Explain question", description: "Explain what this means"
     - multiSelect: false

     Response handling:
     - If "List available features": scan .workspace/features/ and show numbered list
     - If "Enter shorter path": wait for user to type shorter path

   **Allowed pattern:** `^[a-zA-Z0-9/_-]+$`

4. **Parse user input and locate folder:**
   - If input is just a name â†’ search recursively in `.workspace/features/`
   - If input is path with "/" â†’ resolve to specific location
   - Detect type from folder structure and file content:
     - Direct in workspace/ â†’ Feature (new standalone functionality)
     - Has "## Part:" sections in 01-intent.md â†’ Feature with parts (sections, not folders)
     - Has "## Extend:" section in 01-intent.md â†’ Extend mode (context appended)
     - Has "## Change:" section in 01-intent.md â†’ Change mode (context appended)
   - Validate folder exists, otherwise list available options

   **Mode semantics:**
   - **Feature:** New standalone functionality, no parent context needed
   - **Feature with parts:** Decomposed into part sections within 01-intent.md (not separate folders)
   - **Extend:** Adds new capability to existing feature (context in appended sections)
   - **Change:** Modifies existing feature behavior (context in appended sections)

5. **Detect mode and set file paths:**

   **Feature mode (flat):**
   ```
   Intent file: .workspace/features/{name}/01-intent.md
   Research file: .workspace/features/{name}/01-research.md
   Implementation output: .workspace/features/{name}/02-implementation.md
   Tests output: .workspace/features/{name}/02-tests.md
   ```

   **Feature with parts mode (single-file model):**
   ```
   All content in feature folder (parts as sections, not subfolders):
   - Intent: .workspace/features/{name}/01-intent.md (contains "## Part: {NN}-{name}" sections)
   - Research: .workspace/features/{name}/01-research.md (contains "## Part: {NN}-{name}" sections)
   - Implementation: .workspace/features/{name}/02-implementation.md (append part sections)
   - Tests: .workspace/features/{name}/02-tests.md (append part sections)

   Parts are auto-detected in FASE 0
   ```

   **Extend/Change mode (appended sections in parent files):**
   ```
   All context in parent feature folder:
   - Intent: .workspace/features/{parent}/01-intent.md (look for "## Extend: {name}" section)
   - Research: .workspace/features/{parent}/01-research.md (look for "## Extend: {name}" section)
   - Architecture: .workspace/features/{parent}/01-architecture.md (if exists)
   - Implementation: .workspace/features/{parent}/02-implementation.md (append section)
   - Tests: .workspace/features/{parent}/02-tests.md (append section)
   ```

   Note: Extend/change content is found in sections within parent files, not subfolders.

6. **Load context from files:**

   **Pre-check (before reading):**
   - Verify `01-intent.md` exists in target folder
   - Verify `01-research.md` exists in target folder
   - If EITHER file missing:
     ```
     âŒ Missing context file: {filename}

     Both 01-intent.md and 01-research.md are required.
     Run /1-plan first to generate these files.

     Available features:
     [list from .workspace/features/**/01-intent.md]
     ```

     Use AskUserQuestion tool:
     - header: "Missing Context Files"
     - question: "Required context files are missing. How do you want to proceed?"
     - options:
       - label: "Run /1-plan first (Recommended)", description: "Plan this feature to generate context files"
       - label: "Select different feature", description: "Choose from available features with context"
       - label: "Explain question", description: "Explain what this means"
     - multiSelect: false

     Response handling:
     - If "Run /1-plan first": invoke /1-plan skill with the feature name
     - If "Select different feature": show list of features with existing context files

   **Load ALL files in feature folder:**

   Scan target folder and read ALL existing files for full context:

   | File | Purpose | When Present |
   |------|---------|--------------|
   | `01-intent.md` | Requirements (REQUIRED) | Always |
   | `01-research.md` | Patterns (REQUIRED) | Always |
   | `01-architecture.md` | Architecture blueprint | If FASE 3.5 ran |
   | `00-overview.md` | Feature documentation | If previously implemented |
   | `02-implementation.md` | Previous implementation log | If previously implemented |
   | `02-tests.md` | Previous test plan | If previously implemented |
   | `04-refine-*.md` | Previous refinement logs | If /4-refine ran |
   | `05-refactor-*.md` | Previous refactor logs | If /5-refactor ran |

   **Why load all files:**
   - Extend/change scenarios need full context of what already exists
   - Previous implementation decisions inform new changes
   - Avoid duplicating or conflicting with existing code
   - Understand what tests already cover

   **Parse context containing:**
   - From `01-intent.md`: TASK TYPE, USER REQUEST, REQUIREMENTS, DATA MODELS, CONSTRAINTS
   - From `01-research.md`: ARCHITECTURE, PATTERNS, TESTING STRATEGY, PITFALLS
   - From `01-architecture.md` (if exists): Selected approach, files to create/modify, implementation sequence
   - From `00-overview.md` (if exists): Current feature state, public APIs, integration points
   - From `02-implementation.md` (if exists): Previously created/modified files, architectural decisions made
   - From `02-tests.md` (if exists): Existing test coverage, which REQ-IDs already pass

7. **Parse part dependencies (if part mode):**
   - Look for part section in `01-intent.md`: "## Part: {NN}-{name}"
   - Parse "**Dependencies:**" field in part section
   - For each dependency:
     * Check if implementation section for that part exists in `02-implementation.md`
     * Check part status marker in 01-intent.md (â—‹ pending, â— in_progress, âœ“ completed)
     * If dependency not completed (status not âœ“):
       ```
       âŒ Prerequisite not completed: {dep}

       This part depends on: {dep}
       Complete {dep} first (status shows: {current_status})
       ```
       â†’ Stop and wait for user action
   - Load dependency implementation sections to understand available components
   - **Detect circular dependencies using DFS:**
     * Build dependency graph from part sections in 01-intent.md
     * Use depth-first search with visited/in-progress tracking
     * If cycle detected:
       ```
       âŒ Circular dependency detected: {A} â†’ {B} â†’ {C} â†’ {A}

       Cannot proceed with circular dependencies.
       Review 01-intent.md files and break the cycle by:
       1. Removing one dependency from the chain
       2. Merging dependent parts into one
       3. Restructuring to eliminate the cycle
       ```
       â†’ Stop and wait for user to resolve

8. **Extract dependencies from context:**
   - Parse 01-research.md for mentioned packages/libraries
   - Identify imports referenced in implementation plan
   - Check package.json / requirements.txt / composer.json for existing deps
   - List new dependencies that need installation

   Dependencies to track:
   - External packages (npm, pip, composer)
   - Internal modules (project files)
   - Service dependencies (database, cache, queue)

9. Read `.claude/resources/2-code/references/architecture-patterns-web.md` to load structural guidelines

10. Analyze existing project structure:
   - Identify folders (controllers, models, views, components, config)
   - Detect framework/stack from file patterns
   - Note existing architectural patterns

11. Identify which files need creation vs modification

**Output:**
```
ğŸ” PREPARATION COMPLETE

| Field | Value |
|-------|-------|
| **Mode** | [FEATURE / PART / EXTEND / CHANGE] |
| **Task type** | [FEATURE/EXTEND/CHANGE] |
| **User Request** | [parsed from intent] |

**Context loaded:**

| File | Status | Purpose |
|------|--------|---------|
| 01-intent.md | âœ“ | requirements |
| 01-research.md | âœ“ | patterns |
| 01-architecture.md | [âœ“/âœ—] | blueprint |
| 00-overview.md | âœ“ | feature docs (if exists) |
| 02-implementation.md | âœ“ | previous implementation (if exists) |
| 02-tests.md | âœ“ | existing tests (if exists) |
| 04-refine-*.md | âœ“ | {count} refinements (if exists) |
| 05-refactor-*.md | âœ“ | {count} refactors (if exists) |

[If extend/change:]

| Field | Value |
|-------|-------|
| **Parent feature** | {parent} |
| **Existing implementation** | {summary of what exists} |
| **New sections** | {list from ## Extend/Change sections} |

**Project info:**

| Field | Value |
|-------|-------|
| **Project type** | [Backend/Frontend/Full-stack] |
| **Stack detected** | [Framework/libraries] |
| **Files to create** | [list] |
| **Files to modify** | [list] |
| **Implementation saved to** | {implementation-path} |
| **Tests saved to** | {tests-path} |
```

---

### FASE 1.5: APPROACH DETECTION

**Goal:** Detect if feature is simple (direct implementation) or complex (requires architectural choice).

**Reference:** Read `.claude/resources/2-code/references/approach-detection.md` for full detection logic and metrics.

**Steps:**

1. **Analyze feature complexity:**

   Check against criteria from approach-detection.md:

   | Criterion | Simple | Complex |
   |-----------|--------|---------|
   | Files affected | â‰¤ 3 | > 5 |
   | New dependencies | 0 | â‰¥ 1 major |
   | Pattern exists | Yes | No |
   | Architectural choice | None | Multiple valid |
   | Integration points | â‰¤ 2 | > 3 |

2. **Detect architectural choices:**

   Scan requirements for signals indicating multiple valid approaches:
   - Communication: REST vs GraphQL vs gRPC
   - Real-time: Polling vs WebSocket vs SSE
   - State management: Redux vs Context vs Zustand
   - Authentication: JWT vs Session vs OAuth
   - etc.

3. **Route based on detection:**

   **IF SIMPLE (no architectural choice):**
   ```
   ğŸ” ANALYSE: Simpele feature gedetecteerd

   {Feature description}:
   - Geen architectural keuze nodig
   - Bestaand pattern: {pattern name}
   - Bestanden: {count}

   â†’ Direct implementeren...
   ```
   â†’ Skip to FASE 2, run agents silently, auto-synthesize

   **IF COMPLEX with architectural choice:**
   ```
   ğŸ” ANALYSE: Architectural keuze gedetecteerd

   Er zijn {N} fundamenteel verschillende aanpakken:

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ A) {Approach Name}                                          â”‚
   â”‚                                                             â”‚
   â”‚    Complexity:   {â—â—â—‹â—‹â—‹}                                    â”‚
   â”‚    Success kans: {~XX%}                                     â”‚
   â”‚    Risico's:     {specific risks}                           â”‚
   â”‚                                                             â”‚
   â”‚    + {pro 1}                                                â”‚
   â”‚    - {con 1}                                                â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ B) {Approach Name}                                          â”‚
   â”‚                                                             â”‚
   â”‚    Complexity:   {â—â—â—â—‹â—‹}                                    â”‚
   â”‚    Success kans: {~XX%}                                     â”‚
   â”‚    Risico's:     {specific risks}                           â”‚
   â”‚                                                             â”‚
   â”‚    + {pro 1}                                                â”‚
   â”‚    - {con 1}                                                â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   ğŸ“Œ Aanbeveling: Optie {X} ({name})
      Reden: {context-specific reasoning}

   ğŸ§ª Test advies: {Niet nodig / Beide testen aanbevolen}
      {reason}
   ```

   Use AskUserQuestion tool:
   - header: "Approach"
   - question: "Which implementation approach do you want to use?"
   - options:
     - label: "Recommended"
       description: "Use the recommended approach based on codebase analysis"
     - label: "Alternative"
       description: "Use the alternative approach"
   - multiSelect: false

   Response handling:
   - If "Recommended": proceed with recommended approach
   - If "Alternative": proceed with alternative approach

   â†’ Wait for user choice, then proceed to FASE 2 with chosen approach

   **IF COMPLEX without architectural choice:**
   ```
   ğŸ” ANALYSE: Uitgebreide feature gedetecteerd

   {Feature description}:
   - Volgt bestaand pattern: {pattern name}
   - Geen architectural keuze nodig
   - Geschatte bestanden: {count}

   â†’ Implementeren met bestaand pattern...
   ```
   â†’ Proceed to FASE 2 with standard pattern

4. **Metrics calculation:**

   Use qualitative assessment (NOT weighted formulas):

   | Metric | Based On |
   |--------|----------|
   | **Complexity** | File count + dependencies + pattern novelty |
   | **Success kans** | Confidence level (done before? known pattern?) |
   | **Risico's** | Checklist: deps, breaking changes, edge cases, security |

   See approach-detection.md for detailed scales.

**Output:**

```
âœ… APPROACH SELECTED

| Field | Value |
|-------|-------|
| **Detection** | [Simple / Complex with choice / Complex standard] |
| **Approach** | [chosen or auto-selected approach] |
| **Complexity** | {â—â—â—‹â—‹â—‹} |
| **Success kans** | {~XX%} |
| **Risico's** | [list or "None identified"] |

â†’ Proceeding to implementation...
```

---

### FASE 2: IMPLEMENTATION (with Parallel Agents)

**Goal:** Write functional, well-structured code quickly using multiple implementation perspectives for the CHOSEN approach.

**IMPORTANT:** The 3 parallel agents answer HOW to implement the chosen approach (from FASE 1.5), NOT what approach to choose. They optimize execution strategy, not architectural decisions.

**Steps:**

1. **Prepare implementation context:**

   Compile the following for all implementation agents:
   ```
   Feature: [name]
   Tech stack: [from CLAUDE.md]
   Chosen approach: [from FASE 1.5 - e.g., "WebSocket-based real-time"]

   Intent (from 01-intent.md):
   - Requirements: [list]
   - Data models: [description]
   - UI components: [list]
   - Constraints: [list]

   Research (from 01-research.md):
   - Architecture patterns: [relevant patterns]
   - Best practices: [framework conventions]
   - Testing strategy: [test approach]

   Architecture patterns reference: [from architecture-patterns-web.md]

   Existing project structure:
   - [directory tree from FASE 1]
   - [existing patterns in use]
   ```

2. **Launch 3 implementation agents in parallel (single message with 3 Task tool calls):**

   **For simple features (from FASE 1.5):** Run silently, auto-synthesize, no user interaction.

   **For complex features:** Show progress to user.

   ```
   ğŸ”§ Launching implementation analysis for: {chosen approach}

   3 implementation agents optimizing execution:
   - Agent 1: Speed-focused ("Ship fast with {approach}")
   - Agent 2: Quality-focused ("Do it right with {approach}")
   - Agent 3: Balanced ("Pragmatic {approach}")
   ```

   ```
   - Task(subagent_type="implement-speed", prompt="[context above]
     Chosen approach: {approach from FASE 1.5}
     Your mission: Propose a SPEED-FOCUSED implementation of this approach.")

   - Task(subagent_type="implement-quality", prompt="[context above]
     Chosen approach: {approach from FASE 1.5}
     Your mission: Propose a QUALITY-FOCUSED implementation of this approach.")

   - Task(subagent_type="implement-balanced", prompt="[context above]
     Chosen approach: {approach from FASE 1.5}
     Your mission: Propose a BALANCED implementation of this approach.")
   ```

3. **Wait for all 3 agents to complete:**
   - Each agent returns a structured implementation plan
   - **Report progress as agents complete:**
     - Format: `Implementation agents: {completed}/3 complete`
     - Show which agent just finished: `âœ“ implement-speed complete`

4. **Synthesize approaches:**

   Compare the 3 proposals and select best elements:

   ```
   ğŸ“Š IMPLEMENTATION APPROACHES RECEIVED

   | Approach | Files | Effort | Key Trade-off |
   |----------|-------|--------|---------------|
   | Speed | [N] | FAST | [main simplification] |
   | Quality | [N] | THOROUGH | [main investment] |
   | Balanced | [N] | MODERATE | [key trade-off] |

   Synthesis:
   - File structure: [from agent with best organization]
   - Architecture patterns: [from agent with best fit]
   - Execution order: [from agent with best dependencies]
   - Quality investment: [selective from quality agent]
   ```

   **Synthesis rules:**
   - **File structure**: Prefer balanced, unless quality has important separation
   - **Core logic**: Always apply quality-level architecture for business rules
   - **Glue code**: Apply speed-level simplicity for boilerplate
   - **Testing hooks**: Ensure components are testable (from quality agent)
   - **Config separation**: ALWAYS apply (from architecture-patterns-web.md)

5. **Execute synthesized implementation plan:**

   - Work through each file systematically
   - Apply patterns from `.claude/resources/2-code/references/architecture-patterns-web.md`
   - Structure code logically (config â†’ controller â†’ component)
   - Validate each component before moving to next
   - Track progress through implementation

   **Follow these principles:**
   - Focus on making it work first
   - Clear separation where possible (config, controller, component)
   - Config-driven values (no hardcoded colors, magic numbers, endpoints)
   - Extract constants to config section or central config file

6. **For single-file components**, use section markers:
   ```
   // ============================================
   // CONFIG SECTION
   // ============================================

   const CONFIG = {
     primaryColor: '#3B82F6',  // Extracted, not hardcoded in component
     apiEndpoint: '/api/users',
     pageSize: 10
   };

   // ============================================
   // CONTROLLER SECTION
   // ============================================

   function handleData() {
     fetch(CONFIG.apiEndpoint)  // Uses config
   }

   // ============================================
   // COMPONENT SECTION
   // ============================================

   export default Component;
   ```

7. **For multi-file projects**, create central config:
   ```
   config/
   â”œâ”€â”€ theme.css (colors, spacing)
   â”œâ”€â”€ api.config.js (endpoints, timeouts)
   â””â”€â”€ constants.js (magic numbers)
   ```

8. **Keep components plug and play:**
   - Minimize tight coupling
   - Config-driven where possible
   - Easy to swap/modify later
   - No magic values scattered in code

**Do NOT:**
- Perfectionism (that's for /5-refactor)
- Over-engineering
- Style guide enforcement (that's for /5-refactor)
- Performance optimization (unless critical)

**Output:**
```
âœ… IMPLEMENTATION COMPLETE

| Metric | Value |
|--------|-------|
| **Duration** | ~{X} minutes |
| **Files processed** | {N} total ({created} created, {modified} modified) |

**Implementation agents:**

| Agent | Files | Strategy |
|-------|-------|----------|
| implement-speed | {N} | FAST |
| implement-quality | {N} | THOROUGH |
| implement-balanced | {N} | MODERATE |

**Synthesis applied:**

| Aspect | Source Agent |
|--------|--------------|
| File structure | {agent} |
| Architecture | {agent} |
| Quality investment | {selective areas} |

**Created files ({count}):**

| File | Purpose |
|------|---------|
| {path/to/file.ext} | {brief description} |
| {path/to/file.ext} | {brief description} |

**Modified files ({count}):**

| File | Changes |
|------|---------|
| {path/to/file.ext} | {what changed} |
| {path/to/file.ext} | {what changed} |

**Architectural decisions:**

| Decision | Rationale | Source |
|----------|-----------|--------|
| {Decision 1} | {brief rationale} | {agent} |
| {Decision 2} | {brief rationale} | {agent} |

â†’ Proceeding to testing...
```

---

### FASE 3: TESTING

**Goal:** Generate requirement-based test plan and execute automated tests.

**IMPORTANT:** Use `sequential-thinking` tool to systematically analyze and generate tests.

**Fallback if sequential-thinking unavailable:**
If the sequential-thinking MCP tool is not available:
1. Log: `âš ï¸ sequential-thinking not available - using structured internal reasoning`
2. Use explicit test analysis structure:
   ```
   TEST ANALYSIS:
   1. Requirements to test: [list REQ-IDs from 01-intent.md]
   2. Test types per requirement: [mapping]
   3. Edge cases identified: [list]
   4. Test strategy per REQ-ID: [mapping]
   ```
3. Continue with test generation using structured approach

**Steps:**
1. **Load testable requirements from 01-intent.md:**
   - Read the `## Testable Requirements` section
   - Extract all REQ-IDs with their:
     - Description
     - Category (core, api, ui, integration, edge_case)
     - Test type (manual, automated_ui, automated_api, automated_unit)
   - These requirements drive the test structure

2. **Use sequential-thinking to plan tests per requirement:**
   - For each REQ-ID, determine specific test steps
   - Map implementation code to requirements
   - Identify which requirements need automated vs manual tests
   - Plan test scenarios that verify each requirement's acceptance

3. **Generate requirement-based 02-tests.md:**
   ```markdown
   # Test Plan - [Feature Name]
   Generated: [date from time MCP]
   Requirements: [X] testable

   ## Requirements Test Matrix

   | REQ-ID | Description | Test Type | Automated | Manual Steps |
   |--------|-------------|-----------|-----------|--------------|
   | REQ-001 | {description} | {type} | âœ“/âœ— | âœ“/âœ— |
   | REQ-002 | {description} | {type} | âœ“/âœ— | âœ“/âœ— |

   ---

   ## Manual Tests (per Requirement)

   ### REQ-001: {description}
   **Category:** {core/api/ui/integration/edge_case}
   **Test Type:** {manual/automated_ui}

   **Test Steps:**
   1. {Step 1 - specific action}
   2. {Step 2 - specific action}
   3. {Step 3 - verification}

   **Expected Result:**
   - {What should happen when requirement is met}

   ---

   ### REQ-002: {description}
   **Category:** {category}
   **Test Type:** {type}

   **Test Steps:**
   1. {Step 1}
   2. {Step 2}
   3. {Step 3}

   **Expected Result:**
   - {Expected outcome}

   ---

   ## Automated Tests (per Requirement)

   ### REQ-003: {description} (automated_api)
   ```typescript
   // Test code for this requirement
   test('REQ-003: {description}', async () => {
     // Test implementation
   });
   ```

   ### REQ-004: {description} (automated_unit)
   ```typescript
   // Unit test for this requirement
   test('REQ-004: {description}', () => {
     // Test implementation
   });
   ```
   ```

4. **Write automated tests per requirement:**
   - For each REQ-ID with test_type = automated_*
   - Name tests with REQ-ID prefix: `test('REQ-001: description', ...)`
   - Use project's test framework (from claude.md or detect)

5. **Execute automated tests:**
   - Run unit tests
   - Run API tests
   - Report results per REQ-ID

**Output:**
```
âœ… TESTING COMPLETE

| Metric | Value |
|--------|-------|
| **Requirements covered** | {X}/{Y} |
| **Automated tests** | {A} requirements |
| **Manual tests** | {M} requirements |

**Test results:**

| REQ-ID | Status | Type |
|--------|--------|------|
| REQ-001 | âœ“ Pass | automated |
| REQ-002 | âœ“ Pass | automated |
| REQ-003 | â—‹ Ready | manual |
| REQ-004 | â—‹ Ready | manual |

**Manual testing:**

Test plan saved to `.workspace/features/{name}/02-tests.md`

â†’ Run /3-verify to execute manual tests per requirement
```

---

### FASE 4: DOCUMENTATION

**Goal:** Update all project documentation to reflect changes.

**Pre-check: Concurrent execution protection**
Before modifying shared documentation files:
1. Check for lock file: `.claude/.locks/2-code-docs.lock`
2. If lock exists and is < 30 minutes old:
   ```
   âš ï¸ Documentation update in progress

   Another /2-code session is updating docs (started: {timestamp})
   Waiting up to 60 seconds for lock release...
   ```
   â†’ Wait and retry every 5 seconds (max 12 attempts)
3. If lock exists and is > 30 minutes old:
   â†’ Consider stale, remove and proceed with warning
4. Create lock file with current timestamp before proceeding
5. Remove lock file after all documentation updates complete (success or failure)

**Steps:**
1. **Create implementation log:**
   - Use time:get_current_time to fetch current date/time

   **For normal features:**
   - Save to `.workspace/features/{feature-name}/02-implementation.md`

   **For parts (append section to parent file):**
   - Append "## Part: {NN}-{name} ({date})" section to `.workspace/features/{feature}/02-implementation.md`
   - Update part status marker in 01-intent.md from â—‹ to âœ“

   **For extends/changes (append section to parent file):**
   - Append "## Extend: {name} ({date})" section to `.workspace/features/{parent}/02-implementation.md`
   - Or append "## Change: {name} ({date})" section for changes

   - Include:
     - Timestamp of implementation
     - Files created (with paths)
     - Files modified (with paths)
     - Architectural decisions made
     - Deviations from context plan
     - Sequential thinking insights from FASE 2
   - Format:
   ```markdown
   # Implementation Log - {Feature/Part Name}
   Generated: 2025-10-25 14:30:00

   ## Files Created
   - path/to/file.php - [description]

   ## Files Modified
   - path/to/file.php - [what changed]

   ## Architectural Decisions
   - [Decision 1]: [Rationale]

   ## Deviations from Plan
   - [What changed from context and why]

   ## Sequential Thinking Insights
   - [Key insights from FASE 2]
   ```

2. **Save test plan:**

   **For normal features:**
   - Save to `.workspace/features/{feature-name}/02-tests.md`

   **For parts (append section to parent file):**
   - Append "## Part: {NN}-{name} ({date})" section to `.workspace/features/{feature}/02-tests.md`

   - This was generated in FASE 3
   - Ensures all documentation stays together

3. **Execute `scripts/update_architecture.py`:**
   - Scan project structure
   - Identify controllers, models, views, components
   - Generate Mermaid diagrams for relationships
   - Update or create docs/architecture.md

4. **Generate feature overview (00-overview.md):**
   - Create `.workspace/features/{name}/00-overview.md` (adjust path for part/extend/change modes)
   - Parse 01-intent.md for feature purpose and requirements
   - Extract actual endpoints, events, interfaces from implementation
   - Document public APIs and integration points
   - Set Status: Implemented = âœ“ with current date
   - Set Status: Verified = Pending

   **Select template based on project type (from CLAUDE.md):**

   | Project Type | Template Reference |
   |--------------|-------------------|
   | Web (Laravel, React, Vue, Node, etc.) | `.claude/resources/2-code/references/00-overview-web.md` |
   | Game (Unity, Unreal, Godot) | `.claude/resources/2-code/references/00-overview-game.md` |

   **Steps:**
   1. Read project type from `.claude/CLAUDE.md` (look for `## Tech Stack` or similar)
   2. Load the appropriate template reference file
   3. Fill in placeholders with actual implementation data
   4. **Make all file paths clickable links** using markdown: `[{filename}]({path/to/file})`
   5. Omit sections that don't apply (e.g., no API section if no endpoints, no Pending section if empty)
   6. **If extend/change mode:** Remove completed item from `## Pending` table (added by /1-plan)

5. **Execute `scripts/update_docs.py` (Master Documentation Generator):**
   - Reads project type from `.claude/CLAUDE.md`
   - Loads enabled generators from CLAUDE.md
   - Executes relevant documentation generators based on project type:

   **Laravel Backend:**
   - `update_erd.py` â†’ docs/erd.mmd (if database changes)
   - `update_api_docs.py` â†’ docs/api.md
   - `update_components.py` â†’ docs/components.mmd
   - `update_events.py` â†’ docs/events.mmd

   **React Frontend:**
   - `update_components.py` â†’ docs/components.mmd
   - `update_routes.py` â†’ docs/routes.mmd
   - `update_state.py` â†’ docs/state.mmd
   - `update_design_tokens.py` â†’ docs/design-tokens.md

   **Unity Game:**
   - `update_scenes.py` â†’ docs/scenes.mmd
   - `update_game_classes.py` â†’ docs/game-classes.mmd
   - `update_state_machines.py` â†’ docs/state-machines.mmd

   **Other types:** See `.claude/resources/` for full generator lists

   Only enabled generators (configured in CLAUDE.md) will run

**Output:**
```
ğŸ“‹ DOCUMENTATION UPDATED

**Core documentation:**

| Document | Status | Path |
|----------|--------|------|
| Implementation log | âœ“ Updated | {path} |
| Test plan | âœ“ Updated | {path} |
| Feature overview | âœ“ Updated | {path}/00-overview.md |
| Architecture | âœ“ Updated | docs/architecture.md |

**Auto-generated docs (update_docs.py):**

| Generator | Output | Status |
|-----------|--------|--------|
| update_erd.py | docs/erd.mmd | âœ“ |
| update_api_docs.py | docs/api.md | âœ“ |
| update_components.py | docs/components.mmd | âœ“ |
| update_events.py | docs/events.mmd | âœ“ |
```

---

### FASE 5: COMPLETION

**Goal:** Provide clear overview, run quick validation, and prepare handoff to /3-verify.

**Steps:**
1. **Summarize all changes:**
   - Files created
   - Files modified
   - Tests executed (results)
   - Documentation updated

2. **Run quick validation check:**

   Perform automated sanity checks on all created/modified files:

   | Check | What it catches | Severity |
   |-------|-----------------|----------|
   | Syntax errors | Parse errors, malformed code | CRITICAL |
   | Missing imports | Undefined modules/components | CRITICAL |
   | Type errors | TypeScript compilation errors | IMPORTANT |
   | Unused variables | Dead code, forgotten cleanup | SUGGESTION |
   | Console.log statements | Debug code left behind | SUGGESTION |
   | TODO comments | Unfinished work | SUGGESTION |

   ```
   ğŸ” QUICK VALIDATION

   Checking created/modified files...

   âœ… **Passing Checks:**
   - âœ“ No syntax errors
   - âœ“ All imports resolved
   - âœ“ No TypeScript errors

   âš ï¸ **Suggestions (2) - Non-blocking:**
   - [SUGGESTION] Unused variable 'temp' [src/utils/helper.ts:34]
   - [SUGGESTION] Console.log statement [src/components/Cart.tsx:89]

   **Severity Legend:**
   ğŸ”´ [CRITICAL] - Blocks functionality (must fix before proceeding)
   ğŸŸ¡ [IMPORTANT] - Degrades functionality (should fix soon)
   ğŸŸ¢ [SUGGESTION] - Code quality improvement (optional)

   Overall: âœ… READY TO PROCEED (no blocking issues)
   ```

   **If CRITICAL issues found:**
   ```
   âŒ VALIDATION FAILED

   Critical issues must be fixed:
   - Syntax error: Unexpected token [src/auth/login.ts:23]
   - Missing import: 'useState' not imported [src/components/Form.tsx:5]

   Fixing issues before proceeding...
   ```
   â†’ Auto-fix critical issues, then re-validate (MAX 3 ATTEMPTS)

   **Auto-fix retry logic:**
   - Attempt 1 (Direct): Fix exact reported issue
     * Add missing imports
     * Fix syntax errors (missing brackets, semicolons)
     * Correct malformed statements
   - Attempt 2 (Alternative): Try different approach if direct fix failed
     * Use alternative import paths
     * Restructure problematic code
     * Try different API/method
   - Attempt 3 (Conservative): Minimal change to unblock
     * Comment out problematic code with TODO
     * Add try-catch wrapper
     * Revert to simpler implementation
   - If still failing after 3 attempts:
     ```
     âŒ AUTO-FIX FAILED (3 attempts exhausted)

     Remaining issues:
     - [list of unfixed issues]
     ```

     **Use AskUserQuestion tool:**
     - header: "Auto-Fix"
     - question: "Auto-fix failed after 3 attempts. How do you want to proceed?"
     - options:
       1. label: "Fix manually", description: "I'll fix the issues myself and then continue"
       2. label: "Abort", description: "Stop the implementation workflow"

     **Response handling:**
     - "Fix manually" â†’ Wait for user to fix, then re-run validation
     - "Abort" â†’ Exit skill gracefully with summary of what was completed

3. **Analyze next action (multi-part features only):**

   **Skip this step if:** Feature has no parts (single feature mode)

   **For multi-part features, analyze:**

   a. Parse 01-intent.md for all "## Part:" sections
   b. Check status of each part (â—‹ pending, â— in_progress, âœ“ completed)
   c. Identify requirements covered by current part
   d. Classify requirements: automated vs manual test types

   **Decision heuristic:**

   | Situation | Recommendation |
   |-----------|----------------|
   | All REQs automated + pending parts exist | â†’ Next part |
   | Manual UI REQs + standalone testable | â†’ Verify now |
   | Last part completed | â†’ Verify (feature complete) |
   | Foundation part (models/backend only) | â†’ Next part |

   **Output:**
   ```
   ğŸ“Š PART COMPLETION ANALYSE:

   Current: {part-name} âœ“
   Pending: {list of pending parts}

   Requirements covered by this part:
   | REQ-ID | Type | Test Type |
   |--------|------|-----------|
   | REQ-XXX | {category} | automated/manual |

   Aanbeveling: â†’ {Next part / Verify now}
   Reden: {explanation based on heuristic}
   ```

   **Update options display based on analysis:**
   - If recommendation is "Next part":
     ```
     **Beschikbare opties:**
     - **Next Part**: Ga door met het volgende implementation part  â† AANBEVOLEN
     - **Verify Now**: Start verificatie van het voltooide werk
     ```
   - If recommendation is "Verify now":
     ```
     **Beschikbare opties:**
     - **Verify Now**: Start verificatie van het voltooide werk  â† AANBEVOLEN
     - **Next Part**: Ga door met het volgende implementation part
     ```

4. **Identify focus areas for /3-verify:**

   Analyze changes to determine what /3-verify should focus on:
   - New components/features â†’ Test functionality
   - Modified logic â†’ Test edge cases
   - API changes â†’ Test endpoints
   - UI changes â†’ Test visual/responsive

5. **Report status with handoff context**

6. **Offer interactive testing with focus areas:**
   - Ask user if they want to run `/3-verify` now
   - If yes: extract feature path and pass focus areas
   - If no: inform user how to run /3-verify later

**Send notification (after FASE 2-4):**
```bash
powershell -ExecutionPolicy Bypass -File .claude/scripts/notify.ps1 -Title "Claude Code" -Message "Implementation ready"
```

**Output:**
```
âœ… IMPLEMENTATION COMPLETE - READY FOR COMMIT

**Changes:**

| Type | Files |
|------|-------|
| Created | {list of files} |
| Modified | {list of files} |

**Quick Validation:**

| Check | Status |
|-------|--------|
| Syntax | âœ… Pass |
| Imports | âœ… Pass |
| Types | âœ… Pass |
| Suggestions | âš ï¸ {count} (non-blocking) |

**Severity Legend:** ğŸ”´ CRITICAL | ğŸŸ¡ IMPORTANT | ğŸŸ¢ SUGGESTION

| Metric | Status |
|--------|--------|
| Tests | {X}/{Y} passed |
| Documentation | âœ“ Updated |
| Architecture | âœ“ Applied |

**Documentation saved:**

| Document | Path |
|----------|------|
| Implementation | {implementation-file-path} |
| Tests | {tests-file-path} |

**Manual Testing Focus:**

| Priority | Component | Type | Focus |
|----------|-----------|------|-------|
| 1 (Critical) | {Component 1} | new | Test core functionality |
| 2 (Important) | {Component 2} | modified | Test edge cases |
| 2 (Important) | {API endpoint} | new | Test request/response |
| 3 (Nice to have) | {UI component} | modified | Test responsive layout |

[If multi-part with pending parts, show part analysis:]
ğŸ“Š PART COMPLETION ANALYSE:

Current: {part-name} âœ“
Pending: {list of pending parts}

Requirements covered:
| REQ-ID | Type | Test Type |
|--------|------|-----------|
| REQ-XXX | {category} | automated/manual |

Aanbeveling: â†’ {Next part / Verify now}
Reden: {explanation}
```

Use AskUserQuestion tool:
- header: "Next Step"
- question: "Part complete. What do you want to do next?"
- options:
  - label: "Next Part"
    description: "Continue with the next implementation part"
  - label: "Verify Now"
    description: "Run verification on completed work"
- multiSelect: false

Response handling:
- If "Next Part": proceed to next part (invoke /2-code {feature})
- If "Verify Now": switch to /3-verify (invoke /3-verify {feature} with focus areas)

**If user skips or declines:**
```
ğŸ“‹ NEXT STEPS:
1. Review changes
2. Run recommended command later (see NEXT COMMAND below)
3. Focus areas saved in tests file for reference
```

**Show copyable next command:**

After completion (regardless of user choice 1 or 2), always display the recommended next command:

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“‹ NEXT COMMAND (copy after /clear):

[If recommendation is "Next part":]
/2-code {feature-name}

[If recommendation is "Verify now" OR single feature OR last part:]
/3-verify {feature-name}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

**Auto-commit changes (after user selects "Next Part" or "Verify Now"):**
```bash
git add .
git commit -m "$(cat <<'EOF'
code({name}): {summary}

{description}
EOF
)"
```

**Commit message format:**
- `{name}`: Feature/part name
- `{summary}`: One-line summary (e.g., "Implement checkout feature")
- `{description}`: 2-3 lines describing what was implemented:
  - Files created/modified count
  - Key components added
  - Architecture patterns applied

**IMPORTANT:** Do NOT add Co-Authored-By, ğŸ¤– Generated with Claude Code, or any other footer to pipeline commits.

---

## Best Practices

### Language
Follow the Language Policy in CLAUDE.md.

### Workflow Execution
- Execute all six phases sequentially (FASE 0 â†’ 1 â†’ 1.5 â†’ 2 â†’ 3 â†’ 4 â†’ 5)
- FASE 1.5 may pause for user input if architectural choice detected
- Only stop if critical errors occur that block progress
- Report clear status at each phase transition
- Keep momentum - "make it work" is the priority

### Approach Detection (FASE 1.5)
- **ALWAYS read `.claude/resources/2-code/references/approach-detection.md`** for detection logic
- **Simple features** (â‰¤3 files, no new deps, existing pattern): Skip user choice, direct implementation
- **Complex features with choice**: Present options with metrics (complexity, success chance, risks)
- **Complex features without choice**: Inform user, proceed with standard pattern
- **Metrics are qualitative**, not calculated formulas - based on confidence and concrete indicators
- **Agents run AFTER approach selection** - they optimize HOW, not WHAT

### Implementation Agents (FASE 2)
- **FASE 2 uses 3 parallel implementation agents** for the CHOSEN approach (from FASE 1.5):
  - **implement-speed**: "Ship fast with {approach}" - minimal changes, reuse existing code
  - **implement-quality**: "Do it right with {approach}" - clean architecture, testable, SOLID
  - **implement-balanced**: "Pragmatic {approach}" - right-sized for the situation
- **Agents answer HOW to implement, not WHAT to implement** (architectural choice already made)
- **For simple features**: Run silently, auto-synthesize, no user interaction
- **For complex features**: Show progress to user
- **Launch all 3 agents in single message** with 3 Task tool calls (parallel execution)
- **Synthesize best elements** from all 3 approaches:
  - File structure: from balanced (unless quality has important separation)
  - Core logic: always quality-level architecture for business rules
  - Glue code: speed-level simplicity for boilerplate
  - Config separation: ALWAYS apply
- **Report synthesis decisions** with attribution to source agent

### Sequential Thinking Usage
- **FASE 3 (Testing)**: ALWAYS use sequential-thinking to:
  - Analyze code changes systematically
  - Identify what needs testing
  - Determine test strategy per component
  - Generate structured test plan
  - Write tests methodically
  - Validate test coverage

### Implementation Speed
- Focus on functionality first, not perfection
- Write clean code, but don't over-engineer
- Trust that /5-refactor will polish later
- Avoid premature optimization

### Architecture Patterns
- ALWAYS read `.claude/resources/2-code/references/architecture-patterns-web.md` before implementation
- Apply config â†’ controller â†’ component separation
- Use section markers in single-file components
- Extract config values (colors, spacing, endpoints, magic numbers)
- Create central config files (theme.css, api.config.js, constants.js)
- No hardcoded values in components
- Keep components plug and play
- Minimize tight coupling
- Make config easy to modify without touching logic

### Testing Strategy
- **Load testable requirements from 01-intent.md** in FASE 3
- **Organize tests per REQ-ID**, not per component
- Write automated tests for requirements with test_type = automated_*
- Name tests with REQ-ID prefix: `test('REQ-001: description', ...)`
- Generate manual test steps for each requirement
- Keep tests focused and fast
- 02-tests.md must have test steps per REQ-ID for /3-verify

### Documentation Discipline
- ALWAYS update docs/architecture.md when structure changes
- ALWAYS execute update_docs.py to update all enabled documentation generators
- Keep Mermaid diagrams simple and readable

### Error Handling
- If scripts fail: report error and suggest manual alternative
- If tests fail: report which tests and why
- If documentation update fails: continue but flag the issue
- Never silently skip phases

### Communication
- Clear phase transitions
- Concise status reports
- Actionable next steps
- No unnecessary verbosity

### Notifications
- **Notify when Claude waits for user input AFTER a long-running phase**
- Notification moments:
  - FASE 5 start (after FASE 2-4 implementation): "Implementation ready"
- Use the shared script: `.claude/scripts/notify.ps1` with `-Title` and `-Message` parameters
- Never skip notifications - user may be away from screen during agent execution

## Error Handling

### Script Execution Failures

**Problem:** `update_architecture.py` fails
- **Cause:** Unable to scan project structure or generate Mermaid
- **Action:** Create basic docs/architecture.md without diagrams
- **Fallback:** Report to user and continue

**Problem:** `update_erd.py` fails
- **Cause:** No models/migrations found or unable to parse
- **Action:** Skip ERD generation and report to user
- **Fallback:** Continue without ERD update

**Problem:** `update_docs.py` fails
- **Cause:** Project type not found in CLAUDE.md or generator scripts missing
- **Action:** Report error with specific generator that failed
- **Fallback:** Continue with manual documentation or run /setup to configure

**Problem:** `generate_test_plan.py` fails
- **Cause:** Unable to analyze code or create TESTS.md
- **Action:** Manually create TESTS.md structure
- **Fallback:** Report to user and continue

### Time MCP Failures

**Problem:** `time:get_current_time` fails
- **Cause:** MCP server unavailable
- **Action:** Use fallback date format: `YYYY-MM-DD HH:MM:SS [ESTIMATED]`
- **Fallback format example:** `2025-11-30 14:30:00 [ESTIMATED]`
- **Alternative:** Ask user: "Time service unavailable. Enter current date (YYYY-MM-DD):"
- Flag all timestamps with âš ï¸ when using estimated date

### Test Execution Failures

**Problem:** Unit tests fail
- **Cause:** Code has bugs or test framework issues
- **Action:** Report which tests failed and why
- **Next:** User decides to fix or proceed

**Problem:** API tests fail
- **Cause:** Endpoints not working or server issues
- **Action:** Report which endpoints failed
- **Next:** User decides to fix or proceed

**Problem:** Test framework not detected
- **Cause:** No test configuration found
- **Action:** Ask user which test framework to use
- **Fallback:** Create basic test structure and inform user

### File Operation Failures

**Problem:** Cannot create file
- **Cause:** Permission issues or invalid path
- **Action:** Report error with specific file path
- **Fallback:** Suggest manual creation and continue

**Problem:** Cannot modify file
- **Cause:** File locked or doesn't exist
- **Action:** Report error and skip modification
- **Fallback:** Add to REFACTOR_QUEUE for manual review

**Problem:** Cannot read reference file
- **Cause:** `architecture-patterns-web.md` missing
- **Action:** Report missing file and continue with defaults
- **Fallback:** Use basic patterns without reference

### Context Parsing Failures

**Problem:** Cannot find context file in docs/
- **Cause:** User specified file that doesn't exist
- **Action:** List available context files in .workspace/features/ (recursively find all 01-intent.md files)
- **Fallback:** Ask user to run /1-plan first or provide context directly

**Problem:** Cannot parse context from file
- **Cause:** Malformed or missing context block in docs/ file
- **Action:** Ask user for clarification
- **Fallback:** Proceed with direct user instructions

**Problem:** Stack detection fails
- **Cause:** Unfamiliar project structure
- **Action:** Ask user for stack information
- **Fallback:** Use generic approach without stack-specific patterns

### Sequential Thinking Failures

**Problem:** Sequential thinking gets stuck or loops
- **Cause:** Complex problem or unclear requirements
- **Action:** Break down problem differently
- **Fallback:** Report to user and ask for guidance

**Problem:** Sequential thinking produces invalid plan
- **Cause:** Misunderstanding of requirements
- **Action:** Review context and restart planning phase
- **Fallback:** Ask user to clarify requirements

### Recovery Strategy

When errors occur:
1. Report clear error message with context
2. Attempt automatic recovery if possible
3. Fall back to manual alternative
4. NEVER silently skip critical steps
5. Continue to next phase if error is non-blocking
6. Flag issues in completion report

## Restrictions

This skill must NEVER:
- Skip asking for file name/path from user at start of FASE 1
- Proceed without loading context from specified file
- **Skip reading existing files** (00-overview.md, 02-implementation.md, 02-tests.md) when present in feature folder
- **Ignore previous implementation context** in extend/change scenarios
- Skip any of the six phases without critical error (FASE 0 â†’ 1 â†’ 1.5 â†’ 2 â†’ 3 â†’ 4 â†’ 5)
- **Skip FASE 1.5 approach detection** - always analyze simple vs complex
- **Skip reading `references/approach-detection.md`** before FASE 1.5
- **Use weighted formulas for metrics** - use qualitative assessment instead
- **Ask user to choose for simple features** - auto-synthesize and proceed
- Skip launching 3 implementation agents (implement-speed, implement-quality, implement-balanced) in FASE 2
- Proceed without using sequential-thinking in FASE 3
- Proceed without reading `references/architecture-patterns-web.md` in FASE 1
- Commit code automatically (user does commits manually)
- Over-engineer or perfectionism (that's for /5-refactor)
- Apply style guide enforcement (that's for /5-refactor)
- Skip test generation or execution
- **Generate tests per component instead of per REQ-ID**
- **Skip loading testable requirements from 01-intent.md in FASE 3**
- Skip documentation updates (implementation log, tests, 00-overview.md, update_docs.py execution)
- Silently ignore script failures
- Skip multi-part analysis in FASE 5 (always analyze next action for multi-part features)
- Always recommend /3-verify without analyzing if next part is better (use heuristic)
- Proceed if time MCP fails without fallback or user confirmation
- Hardcode colors, spacing, or magic numbers in components
- Create components without config separation
- Skip section markers in single-file components
- Save documentation files to wrong location (must match context file location pattern)
- Create part folders (parts are sections within parent files, not separate folders)

This skill must ALWAYS:
- Ask user for file name or path at start of FASE 1
- Detect if working with part (via "## Part:" section in 01-intent.md)
- Detect if working with extend (via "## Extend:" section in 01-intent.md)
- Detect if working with change (via "## Change:" section in 01-intent.md)
- **Load ALL files in feature folder** (not just 01-intent.md and 01-research.md)
- **Read existing 00-overview.md, 02-implementation.md, 02-tests.md** if present for full context
- **Use previous implementation context** to avoid conflicts and duplications in extend/change scenarios
- Execute all six phases sequentially (FASE 0 â†’ 1 â†’ 1.5 â†’ 2 â†’ 3 â†’ 4 â†’ 5)
- **Read `references/approach-detection.md`** before FASE 1.5
- **Detect simple vs complex features** using criteria from approach-detection.md
- **For simple features**: auto-synthesize silently, no user interaction
- **For complex features with choice**: present options with metrics, wait for user
- **For complex features without choice**: inform user, proceed with standard pattern
- **Use qualitative metrics** (complexity scale, confidence-based success chance, risk checklist)
- Launch 3 implementation agents in parallel in FASE 2 for the CHOSEN approach
- Synthesize best elements from all 3 implementation approaches before executing code
- Use sequential-thinking for FASE 3 (Testing)
- Read `.claude/resources/2-code/references/architecture-patterns-web.md` before implementation
- Apply central config pattern (theme.css, api.config.js, constants.js)
- Use section markers in single-file components (CONFIG / CONTROLLER / COMPONENT)
- Extract all hardcoded values to config
- Keep components plug and play
- Execute update_docs.py to update all enabled documentation generators
- Save implementation and tests to correct location:
  - Normal: .workspace/features/{name}/02-implementation.md and 02-tests.md
  - Part: Append section to .workspace/features/{feature}/02-implementation.md and 02-tests.md
  - Extend/Change: Append section to .workspace/features/{parent}/02-implementation.md and 02-tests.md
- Update part status marker in 01-intent.md when part is completed (â—‹ â†’ âœ“)
- Generate 00-overview.md with feature documentation for humans
- Execute update_docs.py to update docs/architecture.md, docs/erd.mmd, docs/components.mmd, etc.
- **Load testable requirements from 01-intent.md in FASE 3**
- **Generate 02-tests.md with tests organized per REQ-ID**
- **Name automated tests with REQ-ID prefix**
- Execute automated tests (unit and API)
- Analyze next action in FASE 5 for multi-part features (use heuristic to recommend next part vs verify)
- Offer both /3-verify and /2-code options in FASE 5 with clear recommendation
- Report clear status at each phase transition
- Report errors clearly and attempt recovery
- Flag critical issues that need immediate attention
- Minimize tight coupling between components
- Make config easy to modify without touching logic
- Keep part documentation as sections within parent feature files (single-file model)